{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f857b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------+----+\n",
      "|id |datetime                |name|\n",
      "+---+------------------------+----+\n",
      "|1  |2024-01-01T07:15:25.000Z|John|\n",
      "+---+------------------------+----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql._\n",
       "data_1: org.apache.spark.sql.DataFrame = [id: int, datetime: string ... 1 more field]\n"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql._\n",
    "\n",
    "\n",
    "val data_1 = Seq((1,\"2024-01-01T07:15:25.000Z\", \"John\")).toDF(\"id\", \"datetime\", \"name\")\n",
    "\n",
    "data.show(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f90d6635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------+----+-------------------+\n",
      "|id |datetime                |name|ts                 |\n",
      "+---+------------------------+----+-------------------+\n",
      "|1  |2024-01-01T07:15:25.000Z|John|2024-01-01 07:15:25|\n",
      "+---+------------------------+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.withColumn(\"ts\", date_format(to_timestamp($\"datetime\", \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\"), \n",
    "                                               \"yyyy-MM-dd HH:mm:ss\")).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29bf81be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------------+----+------------------------+\n",
      "|id |datetime1               |name|datetime2               |\n",
      "+---+------------------------+----+------------------------+\n",
      "|1  |2024-01-01T07:15:25.000Z|John|2024-01-02T00:00:01.000Z|\n",
      "+---+------------------------+----+------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "data_2: org.apache.spark.sql.DataFrame = [id: int, datetime1: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val data_2 = Seq((1,\"2024-01-01T07:15:25.000Z\", \"John\", \"2024-01-02T00:00:01.000Z\")\n",
    "                ).toDF(\"id\", \"datetime1\", \"name\", \"datetime2\")\n",
    "\n",
    "data_2.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb5e938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------------+----+-------------------+\n",
      "|id |datetime1          |name|datetime2          |\n",
      "+---+-------------------+----+-------------------+\n",
      "|1  |2024-01-01 07:15:25|John|2024-01-02 00:00:01|\n",
      "+---+-------------------+----+-------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "columns: Array[String] = Array(id, datetime1, name, datetime2)\n",
       "regex: scala.util.matching.Regex = datetime\n",
       "selection: Array[String] = Array(datetime1, datetime2)\n"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val columns = data_2.columns \n",
    "\n",
    "val regex = \"\"\"datetime\"\"\".r\n",
    "\n",
    "val selection = columns.filter(c => regex.findFirstIn(c).isDefined)\n",
    "\n",
    "selection.foldLeft(data_2)((tmp, col) => {\n",
    "    tmp.withColumn(col, date_format(to_timestamp($\"$col\", \"yyyy-MM-dd'T'HH:mm:ss.SSS'Z'\"), \"yyyy-MM-dd HH:mm:ss\"))\n",
    "}).show(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5e8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
