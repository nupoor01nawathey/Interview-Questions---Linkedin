{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fc71d639-ae59-4e15-8969-df3aff53afb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create Delta Table from Databricks Cataglogue -> Create Table for Customer_Updated\n",
    "Change id type to int and timestamp to date while creating a table, read 1st line as a header\n",
    "\n",
    "In Community edition delta tables may get deleted after terminating the cluster, so create new delta table if not found\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8456d9bd-208d-4db4-8fdc-8143cd5b4fdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./reader_factory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "591888c8-5c92-44eb-a251-780b58da205e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./extractor\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fdeafb69-3d96-4a04-8853-b20694e21947",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./transform\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d23279c-3dbe-4d74-9e75-2bf3adefabf9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./loader\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "56c9dca2-a9a7-400e-ac3d-16a223b17da8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"./loader_factory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "138d5969-e1e7-4186-bfca-a14ecff53c21",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class FirstWorkFlow:\n",
    "    \"\"\"\n",
    "    ETL Pipeline to generate data for all customers who bought Airpods just after buying iPhone\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def runner(self):\n",
    "        \n",
    "        # 1. Extract data from all sources\n",
    "        input_dfs = AirpodAfterIPhoneExtract().extract()\n",
    "\n",
    "        # 2. Implement transformation logic\n",
    "        first_transform_df = TransformerOperations().airpord_after_iphone_transform(input_dfs)\n",
    "\n",
    "        # 3. Load transformed date into required sink\n",
    "        AirpodsAfterIPhoneLoader(first_transform_df).sink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "86dcab5c-71dc-4177-8f67-612392328274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class SecondWorkFlow:\n",
    "    \"\"\"\n",
    "    ETL Pipeline to generate data for all customers who bought both Airpods + iPhone products only\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def runner(self):\n",
    "        \n",
    "        # 1. Extract data from all sources\n",
    "        print(\"before AirpodAfterIPhoneExtract / extract\")\n",
    "        input_dfs = AirpodAfterIPhoneExtract().extract()\n",
    "\n",
    "        # 2. Implement transformation logic\n",
    "        print(\"before airpods_and_iphone_transform / transform\")\n",
    "        second_transform_df = TransformerOperations().airpods_and_iphone_transform(input_dfs)\n",
    "\n",
    "        print(\"before AirpodsAndIPhoneLoader / sink\")\n",
    "        # 3. Load transformed date into required sink\n",
    "        AirpodsAndIPhoneLoader(second_transform_df).sink()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2c1830a7-e924-42ad-9c3f-43f275101294",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------------+--------+\n|customer_id|customer_name|          join_date|location|\n+-----------+-------------+-------------------+--------+\n|        105|          Eva|2022-01-01 00:00:00|    Ohio|\n|        106|        Frank|2022-02-01 00:00:00|  Nevada|\n|        107|        Grace|2022-03-01 00:00:00|Colorado|\n|        108|        Henry|2022-04-01 00:00:00|    Utah|\n+-----------+-------------+-------------------+--------+\n\nTransformerOperations / airpods_and_iphone_transform / transaction_input_df\nTransformerOperations / airpods_and_iphone_transform / grouped_df\n+-----------+--------------------------+\n|customer_id|products                  |\n+-----------+--------------------------+\n|107        |[AirPods, iPhone]         |\n|108        |[AirPods, iPhone]         |\n|106        |[AirPods, iPhone, MacBook]|\n|105        |[AirPods, iPhone, MacBook]|\n+-----------+--------------------------+\n\nTransformerOperations / airpods_and_iphone_transform / filtered_df\n+-----------+-----------------+\n|customer_id|         products|\n+-----------+-----------------+\n|        107|[AirPods, iPhone]|\n|        108|[AirPods, iPhone]|\n+-----------+-----------------+\n\n+-----------+-------------+--------+\n|customer_id|customer_name|location|\n+-----------+-------------+--------+\n|        107|        Grace|Colorado|\n|        108|        Henry|    Utah|\n+-----------+-------------+--------+\n\ninside AirpodsAndIPhoneLoader / sink\n"
     ]
    }
   ],
   "source": [
    "class WorkFlowRunner:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def runner(self):\n",
    "        if self.name == \"FirstWorkFlow\":\n",
    "            return FirstWorkFlow().runner()\n",
    "        elif self.name == \"SecondWorkFlow\":\n",
    "            return SecondWorkFlow().runner()\n",
    "        else:\n",
    "            raise ValueError(f\"Not implemented for workflow: {self.name}\")\n",
    "\n",
    "# name = \"FirstWorkFlow\"\n",
    "# workflow_runner = WorkFlowRunner(name).runner()\n",
    "\n",
    "name = \"SecondWorkFlow\"\n",
    "workflow_runner = WorkFlowRunner(name).runner()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb1d367a-400b-4624-8299-debb81690994",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------------+--------+\n|customer_id|customer_name|          join_date|location|\n+-----------+-------------+-------------------+--------+\n|        105|          Eva|2022-01-01 00:00:00|    Ohio|\n|        106|        Frank|2022-02-01 00:00:00|  Nevada|\n|        107|        Grace|2022-03-01 00:00:00|Colorado|\n|        108|        Henry|2022-04-01 00:00:00|    Utah|\n+-----------+-------------+-------------------+--------+\n\nroot\n |-- customer_id: integer (nullable = true)\n |-- customer_name: string (nullable = true)\n |-- join_date: timestamp (nullable = true)\n |-- location: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "# dbfs:/FileStore/tables/Customer_Updated.csv\n",
    "# dbfs:/FileStore/tables/Products_Updated.csv\n",
    "# dbfs:/FileStore/tables/Transaction_Updated.csv\n",
    "\n",
    "## Check if delta table created from 1st cell is properly created or not\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Apple-Analysis\").getOrCreate()\n",
    "\n",
    "input_df = spark.read.format(\"delta\").table(\"default.customer_updated_csv\")\n",
    "    \n",
    "input_df.show()\n",
    "input_df.printSchema()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "apple_analysis",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}