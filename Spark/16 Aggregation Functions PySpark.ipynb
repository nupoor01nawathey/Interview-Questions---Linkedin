{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62341c19-c726-4d7c-94e0-88d6ae5869b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------+----+------+-------+-----------+\n|  id|   name| age|salary|country|       dept|\n+----+-------+----+------+-------+-----------+\n|   1| manish|  26| 20000|  india|         IT|\n|   2|  rahul|null| 40000|germany|engineering|\n|   3|  pawan|  12| 60000|  india|      sales|\n|   4|roshini|  44|  null|     uk|engineering|\n|   5|raushan|  35| 70000|  india|      sales|\n|   6|   null|  29|200000|     uk|         IT|\n|   7|   adam|  37| 65000|     us|         IT|\n|   8|  chris|  16| 40000|     us|      sales|\n|null|   null|null|  null|   null|       null|\n|   7|   adam|  37| 65000|     us|         IT|\n+----+-------+----+------+-------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Aggregate : Collecting something together(usually on number values)\n",
    "count   min     max     avg\n",
    "\"\"\"\n",
    "\n",
    "emp_df = spark.createDataFrame(\n",
    "    [\n",
    "        (1,'manish',26,20000,'india','IT'),\n",
    "        (2,'rahul',None,40000,'germany','engineering'),\n",
    "        (3,'pawan',12,60000,'india','sales'),\n",
    "        (4,'roshini',44,None,'uk','engineering'),\n",
    "        (5,'raushan',35,70000,'india','sales'),\n",
    "        (6,None,29,200000,'uk','IT'),\n",
    "        (7,'adam',37,65000,'us','IT'),\n",
    "        (8,'chris',16,40000,'us','sales'),\n",
    "        (None,None,None,None,None,None),\n",
    "        (7,'adam',37,65000,'us','IT')\n",
    "    ], [\"id\", \"name\", \"age\", \"salary\", \"country\", \"dept\"])\n",
    "\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3cecdad5-205c-4059-8eb9-4cf229bad3cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|name_Count|\n+----------+\n|         8|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "df.count() <----- action\n",
    "df.select(count(\"col\")) <----- transformation\n",
    "\n",
    "count(*) <----- will consider null\n",
    "count(col) <--- will skip null\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "emp_df.count()  # 10\n",
    "emp_df.select(count(\"name\").alias(\"name_Count\")) # transformation\n",
    "emp_df.select(count(\"name\").alias(\"name_Count\")).show() # 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "51f5ab47-243e-4a08-a0a9-d505be2797b4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n|total|\n+-----+\n|   10|\n+-----+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(count(\"*\").alias(\"total\")).show() # 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5e10d206-9161-4b3a-93cf-ac3dbd525885",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+-------+\n|total_sal|max_sal|min_sal|\n+---------+-------+-------+\n|   560000| 200000|  20000|\n+---------+-------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(sum(\"salary\").alias(\"total_sal\"), max(\"salary\").alias(\"max_sal\"), min(\"salary\").alias(\"min_sal\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "70a4a2bf-362e-44ea-90b0-5aacf4bb5b25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+------------------------+\n|sum(salary)|count(salary)|CAST(avg(salary) AS INT)|\n+-----------+-------------+------------------------+\n|     560000|            8|                   70000|\n+-----------+-------------+------------------------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df.select(sum(\"salary\"), count(\"salary\"), avg(\"salary\").cast(\"int\").alias(\"avg_sal\")).show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "16 Aggregation Functions PySpark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}