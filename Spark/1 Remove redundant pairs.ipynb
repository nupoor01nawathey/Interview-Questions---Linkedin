{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34859b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+-------+-------+-------+-------+\n",
      "|brand1 |brand2 |year|custom1|custom2|custom3|custom4|\n",
      "+-------+-------+----+-------+-------+-------+-------+\n",
      "|apple  |samsung|2020|1      |2      |1      |2      |\n",
      "|samsung|apple  |2020|1      |2      |1      |2      |\n",
      "|apple  |samsung|2021|1      |2      |5      |3      |\n",
      "|samsung|apple  |2021|5      |3      |1      |2      |\n",
      "|google |null   |2020|5      |9      |0      |0      |\n",
      "|oneplus|nothing|2020|5      |9      |6      |3      |\n",
      "+-------+-------+----+-------+-------+-------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.functions._\n",
       "import org.apache.spark.sql.expressions._\n",
       "data: org.apache.spark.sql.DataFrame = [brand1: string, brand2: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/* Problem Statement:\n",
    "- For pairs of brands in the same year (e.g. apple/samsung/2020 and samsung/apple/2020) \n",
    "    - if custom1 = custom3 and custom2 = custom4 : then keep only one pair\n",
    "\n",
    "- For pairs of brands in the same year \n",
    "    - if custom1 != custom3 OR custom2 != custom4 : then keep both pairs\n",
    "\n",
    "- For brands that do not have pairs in the same year : keep those rows as well\n",
    "*/\n",
    "\n",
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql.expressions._\n",
    "\n",
    "val data = Seq(\n",
    "  (\"apple\",\"samsung\",2020,1,2,1,2),\n",
    "  (\"samsung\",\"apple\",2020,1,2,1,2),\n",
    "  (\"apple\",\"samsung\",2021,1,2,5,3),\n",
    "  (\"samsung\",\"apple\",2021,5,3,1,2),\n",
    "  (\"google\",null.asInstanceOf[String],2020,5,9,null.asInstanceOf[Int],null.asInstanceOf[Int]),\n",
    "  (\"oneplus\",\"nothing\",2020,5,9,6,3)\n",
    ").toDF(\"brand1\",\"brand2\",\"year\",\"custom1\",\"custom2\",\"custom3\",\"custom4\")\n",
    "\n",
    "data.show(false)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49e4538e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+-------+-------+-------+-------+\n",
      "|brand1 |brand2 |year|custom1|custom2|custom3|custom4|\n",
      "+-------+-------+----+-------+-------+-------+-------+\n",
      "|apple  |samsung|2020|1      |2      |1      |2      |\n",
      "|apple  |samsung|2021|1      |2      |5      |3      |\n",
      "|google |null   |2020|5      |9      |0      |0      |\n",
      "|oneplus|nothing|2020|5      |9      |6      |3      |\n",
      "|samsung|apple  |2021|5      |3      |1      |2      |\n",
      "+-------+-------+----+-------+-------+-------+-------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [brand1#87 ASC NULLS FIRST, year#89 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(brand1#87 ASC NULLS FIRST, year#89 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=293]\n",
      "      +- Project [brand1#87, brand2#88, year#89, custom1#90, custom2#91, custom3#92, custom4#93]\n",
      "         +- Filter ((rn#183 = 1) OR (NOT (custom1#90 = custom3#92) AND NOT (custom2#91 = custom4#93)))\n",
      "            +- Window [row_number() windowspecdefinition(pairs#182, pairs#182 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#183], [pairs#182], [pairs#182 ASC NULLS FIRST]\n",
      "               +- Sort [pairs#182 ASC NULLS FIRST, pairs#182 ASC NULLS FIRST], false, 0\n",
      "                  +- Exchange hashpartitioning(pairs#182, 200), ENSURE_REQUIREMENTS, [plan_id=287]\n",
      "                     +- LocalTableScan [brand1#87, brand2#88, year#89, custom1#90, custom2#91, custom3#92, custom4#93, pairs#182]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df1: org.apache.spark.sql.DataFrame = [brand1: string, brand2: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.createOrReplaceTempView(\"brand_tbl\")\n",
    "\n",
    "val df1 = spark.sql(\"\"\"\n",
    "WITH CTE1 AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        CASE WHEN brand1<brand2 THEN CONCAT(brand1,brand2,year) ELSE CONCAT(brand2,brand1,year) END pairs\n",
    "    FROM brand_tbl  \n",
    "), \n",
    "CTE2 AS (\n",
    "    SELECT \n",
    "        *,\n",
    "        ROW_NUMBER() OVER(PARTITION BY pairs order by pairs) rn\n",
    "    FROM CTE1\n",
    ")  \n",
    "SELECT \n",
    "    brand1,brand2,year,custom1,custom2,custom3,custom4\n",
    "FROM CTE2 WHERE rn=1\n",
    "OR custom1 <> custom3 and custom2 <> custom4\n",
    "ORDER BY brand1, year\n",
    "\"\"\")\n",
    "\n",
    "df1.show(false)\n",
    "df1.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6fdfd2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+----+-------+-------+-------+-------+\n",
      "|brand1 |brand2 |year|custom1|custom2|custom3|custom4|\n",
      "+-------+-------+----+-------+-------+-------+-------+\n",
      "|apple  |samsung|2020|1      |2      |1      |2      |\n",
      "|apple  |samsung|2021|1      |2      |5      |3      |\n",
      "|google |null   |2020|5      |9      |0      |0      |\n",
      "|oneplus|nothing|2020|5      |9      |6      |3      |\n",
      "|samsung|apple  |2021|5      |3      |1      |2      |\n",
      "+-------+-------+----+-------+-------+-------+-------+\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [brand1#87 ASC NULLS FIRST, year#89 ASC NULLS FIRST], true, 0\n",
      "   +- Exchange rangepartitioning(brand1#87 ASC NULLS FIRST, year#89 ASC NULLS FIRST, 200), ENSURE_REQUIREMENTS, [plan_id=533]\n",
      "      +- Project [brand1#87, brand2#88, year#89, custom1#90, custom2#91, custom3#92, custom4#93]\n",
      "         +- Filter ((rn#361 = 1) OR (NOT (custom1#90 = custom3#92) AND NOT (custom2#91 = custom4#93)))\n",
      "            +- Window [row_number() windowspecdefinition(pairs#351, pairs#351 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rn#361], [pairs#351], [pairs#351 ASC NULLS FIRST]\n",
      "               +- Sort [pairs#351 ASC NULLS FIRST, pairs#351 ASC NULLS FIRST], false, 0\n",
      "                  +- Exchange hashpartitioning(pairs#351, 200), ENSURE_REQUIREMENTS, [plan_id=527]\n",
      "                     +- LocalTableScan [brand1#87, brand2#88, year#89, custom1#90, custom2#91, custom3#92, custom4#93, pairs#351]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df2: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [brand1: string, brand2: string ... 5 more fields]\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df2 = data.withColumn(\"pairs\", when($\"brand1\" < $\"brand2\", concat($\"brand1\",$\"brand2\",$\"year\")\n",
    "                             ).otherwise(concat($\"brand2\",$\"brand1\",$\"year\")) \n",
    "    ).withColumn(\"rn\",row_number().over(Window.partitionBy($\"pairs\").orderBy($\"pairs\"))\n",
    "    ).filter($\"rn\" === 1 || ($\"custom1\" =!= $\"custom3\" && $\"custom2\" =!= $\"custom4\")\n",
    "    ).select(\"brand1\",\"brand2\",\"year\",\"custom1\",\"custom2\",\"custom3\",\"custom4\"\n",
    "    ).orderBy($\"brand1\",$\"year\")\n",
    "\n",
    "\n",
    "df2.show(false)\n",
    "df2.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7df163",
   "metadata": {},
   "outputs": [],
   "source": [
    "// SQL stmts\n",
    "\n",
    "// CREATE TABLE brands \n",
    "// (\n",
    "//     brand1      VARCHAR(20),\n",
    "//     brand2      VARCHAR(20),\n",
    "//     year        INT,\n",
    "//     custom1     INT,\n",
    "//     custom2     INT,\n",
    "//     custom3     INT,\n",
    "//     custom4     INT\n",
    "// );\n",
    "// INSERT INTO brands VALUES ('apple', 'samsung', 2020, 1, 2, 1, 2);\n",
    "// INSERT INTO brands VALUES ('samsung', 'apple', 2020, 1, 2, 1, 2);\n",
    "// INSERT INTO brands VALUES ('apple', 'samsung', 2021, 1, 2, 5, 3);\n",
    "// INSERT INTO brands VALUES ('samsung', 'apple', 2021, 5, 3, 1, 2);\n",
    "// INSERT INTO brands VALUES ('google', NULL, 2020, 5, 9, NULL, NULL);\n",
    "// INSERT INTO brands VALUES ('oneplus', 'nothing', 2020, 5, 9, 6, 3);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
