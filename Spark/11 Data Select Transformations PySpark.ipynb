{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64698591-6812-4379-a266-fa25f3059a8f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+------+----------+-----------+\n| id|      name|     age|salary|   address|     gender|\n+---+----------+--------+------+----------+-----------+\n|  1|    Manish|      26|  null|     INDIA|          m|\n|  2|    Nikita|      23|  null|       USA|          f|\n|  3|    Pritam|      22|  null|     INDIA|          m|\n|  4|  Prantosh|      17|  null|     JAPAN|          m|\n|  5|    Vikash|      31|  null|       USA|          m|\n|  6|     Rahul|      55|  null|     INDIA|          m|\n|  7|      Raju|      67|  null|       USA|          m|\n|  8|   Praveen|      28|  null|     JAPAN|          m|\n|  9|       Dev|      32|  null|     JAPAN|          m|\n| 10|    Sherin|      16|  null|    RUSSIA|          f|\n| 11|      Ragu|      12|  null|     INDIA|          f|\n| 12|     Sweta|      43|  null|     INDIA|          f|\n| 13|   Raushan|      48|  null|       USA|          m|\n| 14|    Mukesh|      36|  null|    RUSSIA|          m|\n| 15|   Prakash|      52|  null|     INDIA|          m|\n+---+----------+--------+------+----------+-----------+\n\nroot\n |-- id: integer (nullable = true)\n |-- name: string (nullable = true)\n |-- age: string (nullable = true)\n |-- salary: integer (nullable = true)\n |-- address: string (nullable = true)\n |-- gender: string (nullable = true)\n\nOut[20]: ['id', 'name', 'age', 'salary', 'address', 'gender']"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "myschema = StructType([\n",
    "    StructField(\"id\", IntegerType()),\n",
    "    StructField(\"name\", StringType()),\n",
    "    StructField(\"age\", StringType()),\n",
    "    StructField(\"salary\", IntegerType()),\n",
    "    StructField(\"address\", StringType()),\n",
    "    StructField(\"gender\", StringType())\n",
    "])\n",
    "\n",
    "employee_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .schema(myschema)\\\n",
    "    .load(\"/FileStore/tables/employee_write_data.csv\")\n",
    "\n",
    "employee_df.show()\n",
    "employee_df.printSchema()\n",
    "employee_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8dd8515f-593e-49fd-8599-83e2d42d5694",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|      name|\n+----------+\n|    Manish|\n|    Nikita|\n|    Pritam|\n|  Prantosh|\n|    Vikash|\n|     Rahul|\n|      Raju|\n|   Praveen|\n|       Dev|\n|    Sherin|\n|      Ragu|\n|     Sweta|\n|   Raushan|\n|    Mukesh|\n|   Prakash|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(\"name\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "44c19503-1d62-431e-8569-17f70ae0ba64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n|      name|\n+----------+\n|    Manish|\n|    Nikita|\n|    Pritam|\n|  Prantosh|\n|    Vikash|\n|     Rahul|\n|      Raju|\n|   Praveen|\n|       Dev|\n|    Sherin|\n|      Ragu|\n|     Sweta|\n|   Raushan|\n|    Mukesh|\n|   Prakash|\n+----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "employee_df.select(col(\"name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d31c4eb5-b61d-412b-8cdd-a19a75169e93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n|(id + 5)|\n+--------+\n|       6|\n|       7|\n|       8|\n|       9|\n|      10|\n|      11|\n|      12|\n|      13|\n|      14|\n|      15|\n|      16|\n|      17|\n|      18|\n|      19|\n|      20|\n+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(col(\"id\") + 5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0dd9e9f-bcd2-410e-af84-7d2712e62d3e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+\n| id|      name|     age|\n+---+----------+--------+\n|  1|    Manish|      26|\n|  2|    Nikita|      23|\n|  3|    Pritam|      22|\n|  4|  Prantosh|      17|\n|  5|    Vikash|      31|\n|  6|     Rahul|      55|\n|  7|      Raju|      67|\n|  8|   Praveen|      28|\n|  9|       Dev|      32|\n| 10|    Sherin|      16|\n| 11|      Ragu|      12|\n| 12|     Sweta|      43|\n| 13|   Raushan|      48|\n| 14|    Mukesh|      36|\n| 15|   Prakash|      52|\n+---+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(\"id\", \"name\", \"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4ddbbe9-d8a0-44e2-9a74-34d7926753ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------+----------+\n| id|      name|salary|   address|\n+---+----------+------+----------+\n|  1|    Manish|  null|     INDIA|\n|  2|    Nikita|  null|       USA|\n|  3|    Pritam|  null|     INDIA|\n|  4|  Prantosh|  null|     JAPAN|\n|  5|    Vikash|  null|       USA|\n|  6|     Rahul|  null|     INDIA|\n|  7|      Raju|  null|       USA|\n|  8|   Praveen|  null|     JAPAN|\n|  9|       Dev|  null|     JAPAN|\n| 10|    Sherin|  null|    RUSSIA|\n| 11|      Ragu|  null|     INDIA|\n| 12|     Sweta|  null|     INDIA|\n| 13|   Raushan|  null|       USA|\n| 14|    Mukesh|  null|    RUSSIA|\n| 15|   Prakash|  null|     INDIA|\n+---+----------+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "employee_df[\"salary\"] ---> Used for join\n",
    "\"\"\"\n",
    "employee_df.select(\"id\", col(\"name\"), employee_df[\"salary\"], employee_df.address).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07e8d42a-f66f-48a2-ac29-7b082682bc8a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------------------+\n|employee_id|(id + 5)|  name_and_address|\n+-----------+--------+------------------+\n|          1|       6|   Manish    INDIA|\n|          2|       7|      Nikita   USA|\n|          3|       8|    Pritam   INDIA|\n|          4|       9|  Prantosh   JAPAN|\n|          5|      10|      Vikash   USA|\n|          6|      11|     Rahul   INDIA|\n|          7|      12|        Raju   USA|\n|          8|      13|  Praveen    JAPAN|\n|          9|      14|       Dev   JAPAN|\n|         10|      15|  Sherin    RUSSIA|\n|         11|      16|     Ragu    INDIA|\n|         12|      17|     Sweta   INDIA|\n|         13|      18|     Raushan   USA|\n|         14|      19|  Mukesh    RUSSIA|\n|         15|      20|   Prakash   INDIA|\n+-----------+--------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(expr(\"id as employee_id\"), expr(\"id + 5\"), expr(\"concat(name,address) as name_and_address\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cf19842-739c-451b-aee3-1192fe5dfa64",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------+------+----------+-----------+\n| id|      name|     age|salary|   address|     gender|\n+---+----------+--------+------+----------+-----------+\n|  1|    Manish|      26|  null|     INDIA|          m|\n|  2|    Nikita|      23|  null|       USA|          f|\n|  3|    Pritam|      22|  null|     INDIA|          m|\n|  4|  Prantosh|      17|  null|     JAPAN|          m|\n|  5|    Vikash|      31|  null|       USA|          m|\n|  6|     Rahul|      55|  null|     INDIA|          m|\n|  7|      Raju|      67|  null|       USA|          m|\n|  8|   Praveen|      28|  null|     JAPAN|          m|\n|  9|       Dev|      32|  null|     JAPAN|          m|\n| 10|    Sherin|      16|  null|    RUSSIA|          f|\n| 11|      Ragu|      12|  null|     INDIA|          f|\n| 12|     Sweta|      43|  null|     INDIA|          f|\n| 13|   Raushan|      48|  null|       USA|          m|\n| 14|    Mukesh|      36|  null|    RUSSIA|          m|\n| 15|   Prakash|      52|  null|     INDIA|          m|\n+---+----------+--------+------+----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.createOrReplaceTempView(\"employee_tbl\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "          select * from employee_tbl\n",
    "          \"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "11 Data Select Transformations PySpark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}