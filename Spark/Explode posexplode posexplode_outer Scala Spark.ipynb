{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0126a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+--------------------+\n",
      "|Name |Age|Courses_enrolled    |\n",
      "+-----+---+--------------------+\n",
      "|Jaya |20 |[SQL, Data, Science]|\n",
      "|Milan|21 |[ML, AI]            |\n",
      "|Rohit|19 |[]                  |\n",
      "|Maria|20 |[DBMS, Networking]  |\n",
      "|Jay  |22 |[]                  |\n",
      "+-----+---+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [Name: string, Age: int ... 1 more field]\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "val df = Seq(\n",
    "    (\"Jaya\", 20, List(\"SQL\", \"Data\", \"Science\")), \n",
    "    (\"Milan\", 21, List(\"ML\", \"AI\")), \n",
    "    (\"Rohit\", 19, List()), \n",
    "    (\"Maria\", 20, List(\"DBMS\", \"Networking\")), \n",
    "    (\"Jay\", 22, List())\n",
    ").toDF(\"Name\", \"Age\", \"Courses_enrolled\")\n",
    "\n",
    "\n",
    "df.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d30448dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----------+\n",
      "|Name |Age|course    |\n",
      "+-----+---+----------+\n",
      "|Jaya |20 |SQL       |\n",
      "|Jaya |20 |Data      |\n",
      "|Jaya |20 |Science   |\n",
      "|Milan|21 |ML        |\n",
      "|Milan|21 |AI        |\n",
      "|Maria|20 |DBMS      |\n",
      "|Maria|20 |Networking|\n",
      "+-----+---+----------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Generate explode(Courses_enrolled#28), [Name#26, Age#27], false, [course#152]\n",
      "+- *(1) LocalTableScan [Name#26, Age#27, Courses_enrolled#28]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "explode_df: org.apache.spark.sql.DataFrame = [Name: string, Age: int ... 1 more field]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    "    NOTE that if exploding column has Empty List all such records will be dropped by Spark itself\n",
    "*/\n",
    "\n",
    "val explode_df = df.withColumn(\"course\", explode($\"Courses_enrolled\")).drop(\"Courses_enrolled\")\n",
    "\n",
    "explode_df.show(false)\n",
    "explode_df.explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49c26992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+---+----------+\n",
      "|name |age|pos|col       |\n",
      "+-----+---+---+----------+\n",
      "|Jaya |20 |0  |SQL       |\n",
      "|Jaya |20 |1  |Data      |\n",
      "|Jaya |20 |2  |Science   |\n",
      "|Milan|21 |0  |ML        |\n",
      "|Milan|21 |1  |AI        |\n",
      "|Maria|20 |0  |DBMS      |\n",
      "|Maria|20 |1  |Networking|\n",
      "+-----+---+---+----------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [name#26, age#27, pos#179, col#180]\n",
      "+- *(1) Generate posexplode(Courses_enrolled#28), [Name#26, Age#27], false, [pos#179, col#180]\n",
      "   +- *(1) LocalTableScan [Name#26, Age#27, Courses_enrolled#28]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "posexplode_df: org.apache.spark.sql.DataFrame = [name: string, age: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    "    NOTE that outerexplode have to be used in a select expression, it will output \n",
    "    index in pos column\n",
    "    value in col column\n",
    "    \n",
    "    Records with Empty List will be dropped by Spark itself\n",
    "*/\n",
    "\n",
    "val posexplode_df = df.select($\"name\", $\"age\", posexplode($\"Courses_enrolled\"))\n",
    "\n",
    "posexplode_df.show(false)\n",
    "posexplode_df.explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "059689e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+----+----------+\n",
      "|name |age|pos |col       |\n",
      "+-----+---+----+----------+\n",
      "|Jaya |20 |0   |SQL       |\n",
      "|Jaya |20 |1   |Data      |\n",
      "|Jaya |20 |2   |Science   |\n",
      "|Milan|21 |0   |ML        |\n",
      "|Milan|21 |1   |AI        |\n",
      "|Rohit|19 |null|null      |\n",
      "|Maria|20 |0   |DBMS      |\n",
      "|Maria|20 |1   |Networking|\n",
      "|Jay  |22 |null|null      |\n",
      "+-----+---+----+----------+\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [name#26, age#27, pos#225, col#226]\n",
      "+- *(1) Generate posexplode(Courses_enrolled#28), [Name#26, Age#27], true, [pos#225, col#226]\n",
      "   +- *(1) LocalTableScan [Name#26, Age#27, Courses_enrolled#28]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "posexplode_outer_df: org.apache.spark.sql.DataFrame = [name: string, age: int ... 2 more fields]\n"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "/*\n",
    "    NOTE that outerexplode have to be used in a select expression, it will output \n",
    "    index in pos column\n",
    "    value in col column\n",
    "    \n",
    "    Records with Empty List will be CONSIDERED IN THE OUTPUT\n",
    "*/\n",
    "\n",
    "val posexplode_outer_df = df.select($\"name\", $\"age\", posexplode_outer($\"Courses_enrolled\"))\n",
    "\n",
    "posexplode_outer_df.show(false)\n",
    "posexplode_outer_df.explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458cc07f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
