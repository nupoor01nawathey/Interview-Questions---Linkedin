{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5751ef1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------+-------+----------+------------+\n",
      "|emp_id|emp_name      |emp_gender|emp_age|emp_salary|emp_manager |\n",
      "+------+--------------+----------+-------+----------+------------+\n",
      "|1     |Arjun Patel   |Male      |30     |60000     |Aarav Sharma|\n",
      "|2     |Aarav Sharma  |Male      |28     |55000     |Zara Singh  |\n",
      "|3     |Zara Singh    |Female    |35     |70000     |Arjun Patel |\n",
      "|4     |Priya Reddy   |Female    |32     |65000     |Aarav Sharma|\n",
      "|1     |Arjun Patel   |Male      |30     |60000     |Aarav Sharma|\n",
      "|6     |Naina Verma   |Female    |31     |72000     |Arjun Patel |\n",
      "|1     |Arjun Patel   |Male      |30     |60000     |Aarav Sharma|\n",
      "|4     |Priya Reddy   |Female    |32     |65000     |Aarav Sharma|\n",
      "|5     |Aditya Kapoor |Male      |28     |58000     |Zara Singh  |\n",
      "|10    |Anaya Joshi   |Female    |27     |59000     |Aarav Sharma|\n",
      "|11    |Rohan Malhotra|Male      |36     |73000     |Zara Singh  |\n",
      "|3     |Zara Singh    |Female    |35     |70000     |Arjun Patel |\n",
      "+------+--------------+----------+-------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.Row\n",
       "schema: org.apache.spark.sql.types.StructType = StructType(StructField(emp_id,IntegerType,true),StructField(emp_name,StringType,true),StructField(emp_gender,StringType,true),StructField(emp_age,IntegerType,true),StructField(emp_salary,IntegerType,true),StructField(emp_manager,StringType,true))\n",
       "data: Seq[org.apache.spark.sql.Row] = List([1,Arjun Patel,Male,30,60000,Aarav Sharma], [2,Aarav Sharma,Male,28,55000,Zara Singh], [3,Zara Singh,Female,35,70000,Arjun Patel], [4,Priya Reddy,Female,32,65000,Aarav Sharma], [1,Arjun Patel,Male,30,60000,Aarav Sharma], [6,Naina Verma,Female,31,72000,Arjun Patel], [1,Arjun Patel,Male,30,60000,Aarav Sharma], [4,Priya Reddy,Female,32,65000,Aarav Sharma], [5,Aditya Kapoor,Male,28,58000,Zara...\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._\n",
    "import org.apache.spark.sql.Row\n",
    "\n",
    "\n",
    "val schema = StructType(Array(\n",
    "    StructField(\"emp_id\", IntegerType),\n",
    "    StructField(\"emp_name\", StringType),\n",
    "    StructField(\"emp_gender\", StringType),\n",
    "    StructField(\"emp_age\", IntegerType),\n",
    "    StructField(\"emp_salary\", IntegerType),\n",
    "    StructField(\"emp_manager\", StringType)\n",
    "))\n",
    "\n",
    "val data = Seq(\n",
    "    Row(1, \"Arjun Patel\", \"Male\", 30, 60000, \"Aarav Sharma\"),\n",
    "    Row(2, \"Aarav Sharma\", \"Male\", 28, 55000, \"Zara Singh\"),\n",
    "    Row(3, \"Zara Singh\", \"Female\", 35, 70000, \"Arjun Patel\"),\n",
    "    Row(4, \"Priya Reddy\", \"Female\", 32, 65000, \"Aarav Sharma\"),\n",
    "    Row(1, \"Arjun Patel\", \"Male\", 30, 60000, \"Aarav Sharma\"),\n",
    "    Row(6, \"Naina Verma\", \"Female\", 31, 72000, \"Arjun Patel\"),\n",
    "    Row(1, \"Arjun Patel\", \"Male\", 30, 60000, \"Aarav Sharma\"),\n",
    "    Row(4, \"Priya Reddy\", \"Female\", 32, 65000, \"Aarav Sharma\"),\n",
    "    Row(5, \"Aditya Kapoor\", \"Male\", 28, 58000, \"Zara Singh\"),\n",
    "    Row(10,\"Anaya Joshi\", \"Female\", 27, 59000, \"Aarav Sharma\"),\n",
    "    Row(11,\"Rohan Malhotra\", \"Male\", 36, 73000, \"Zara Singh\"),\n",
    "    Row(3, \"Zara Singh\", \"Female\", 35, 70000, \"Arjun Patel\")\n",
    ")\n",
    "\n",
    "val rdd = spark.sparkContext.parallelize(data)\n",
    "val df = spark.createDataFrame(rdd, schema)\n",
    "\n",
    "df.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "decdaf9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "df_groupBy: Array[String] = Array(emp_id, emp_name, emp_gender, emp_age, emp_salary, emp_manager)\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val df_groupBy = df.columns // what if there are 100s of columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "596daf40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+----------+-------+----------+------------+\n",
      "|emp_id|emp_name   |emp_gender|emp_age|emp_salary|emp_manager |\n",
      "+------+-----------+----------+-------+----------+------------+\n",
      "|1     |Arjun Patel|Male      |30     |60000     |Aarav Sharma|\n",
      "|3     |Zara Singh |Female    |35     |70000     |Arjun Patel |\n",
      "|4     |Priya Reddy|Female    |32     |65000     |Aarav Sharma|\n",
      "+------+-----------+----------+-------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "grouped_df: org.apache.spark.sql.DataFrame = [emp_id: int, emp_name: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val grouped_df = df.groupBy(df_groupBy.head, df_groupBy.tail:_*).count().where($\"count\">1).drop($\"count\")\n",
    "\n",
    "grouped_df.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d816d867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+----------+-------+----------+------------+\n",
      "|emp_id|emp_name      |emp_gender|emp_age|emp_salary|emp_manager |\n",
      "+------+--------------+----------+-------+----------+------------+\n",
      "|1     |Arjun Patel   |Male      |30     |60000     |Aarav Sharma|\n",
      "|3     |Zara Singh    |Female    |35     |70000     |Arjun Patel |\n",
      "|2     |Aarav Sharma  |Male      |28     |55000     |Zara Singh  |\n",
      "|6     |Naina Verma   |Female    |31     |72000     |Arjun Patel |\n",
      "|4     |Priya Reddy   |Female    |32     |65000     |Aarav Sharma|\n",
      "|5     |Aditya Kapoor |Male      |28     |58000     |Zara Singh  |\n",
      "|11    |Rohan Malhotra|Male      |36     |73000     |Zara Singh  |\n",
      "|10    |Anaya Joshi   |Female    |27     |59000     |Aarav Sharma|\n",
      "+------+--------------+----------+-------+----------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dropped_df: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [emp_id: int, emp_name: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dropped_df = df.dropDuplicates()\n",
    "\n",
    "dropped_df.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baf0f07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
