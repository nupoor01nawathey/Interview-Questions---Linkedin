{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bcedda12-7faf-48a2-9690-9b4711a20193",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+-------+------+--------------------+------------------+\n| id|  name|   city|country|active|effective_start_date|effective_end_date|\n+---+------+-------+-------+------+--------------------+------------------+\n|  1|manish|  arwal|  india|     N|          2022-09-15|        2022-09-25|\n|  2|vikash|  patna|  india|     Y|          2023-08-12|              null|\n|  3|nikita|  delhi|  india|     Y|          2023-09-10|              null|\n|  4|rakesh| jaipur|  india|     Y|          2023-06-10|              null|\n|  5| ayush|     NY|    USA|     Y|          2023-06-10|              null|\n|  1|manish|gurgaon|  india|     Y|          2022-09-25|              null|\n+---+------+-------+-------+------+--------------------+------------------+\n\n+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n|sales_id|customer_id|customer_name|sales_date|food_delivery_address|food_delivery_country|food_cost|\n+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n|       1|          1|       manish|2023-01-16|              gurgaon|                india|      380|\n|      77|          1|       manish|2023-03-11|            bangalore|                india|      300|\n|      12|          3|       nikita|2023-09-20|                delhi|                india|      127|\n|      54|          4|       rakesh|2023-08-10|               jaipur|                india|      321|\n|      65|          5|        ayush|2023-09-07|                mosco|               russia|      765|\n|      89|          6|        rajat|2023-08-10|               jaipur|                india|      321|\n+--------+-----------+-------------+----------+---------------------+---------------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "We are going to identify Type 2 rows on the basis of change in address\n",
    "If we have to identify changes in any field then better to create md5 hash and store that in fact sales_df and use that to filter new or update records\n",
    "\"\"\"\n",
    "\n",
    "customer_dim_data = [\n",
    "    (1,'manish','arwal','india','N','2022-09-15','2022-09-25'),\n",
    "    (2,'vikash','patna','india','Y','2023-08-12',None),\n",
    "    (3,'nikita','delhi','india','Y','2023-09-10',None),\n",
    "    (4,'rakesh','jaipur','india','Y','2023-06-10',None),\n",
    "    (5,'ayush','NY','USA','Y','2023-06-10',None),\n",
    "    (1,'manish','gurgaon','india','Y','2022-09-25',None),\n",
    "]\n",
    "customer_schema= ['id','name','city','country','active','effective_start_date','effective_end_date']\n",
    "customer_dim_df = spark.createDataFrame(data= customer_dim_data,schema=customer_schema)\n",
    "\n",
    "sales_data = [\n",
    "    (1,1,'manish','2023-01-16','gurgaon','india',380),\n",
    "    (77,1,'manish','2023-03-11','bangalore','india',300),\n",
    "    (12,3,'nikita','2023-09-20','delhi','india',127),\n",
    "    (54,4,'rakesh','2023-08-10','jaipur','india',321),\n",
    "    (65,5,'ayush','2023-09-07','mosco','russia',765),\n",
    "    (89,6,'rajat','2023-08-10','jaipur','india',321)\n",
    "]\n",
    "sales_schema = ['sales_id', 'customer_id','customer_name', 'sales_date', 'food_delivery_address','food_delivery_country', 'food_cost']\n",
    "sales_df = spark.createDataFrame(data=sales_data,schema=sales_schema)\n",
    "\n",
    "customer_dim_df.show() # dim target/trgt data",
    "sales_df.show()        # incoming source/src data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5181f794-21e0-4254-9cb1-0ca6e088d322",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>id</th><th>name</th><th>city</th><th>country</th><th>active</th><th>effective_start_date</th><th>effective_end_date</th><th>sales_id</th><th>customer_id</th><th>customer_name</th><th>sales_date</th><th>food_delivery_address</th><th>food_delivery_country</th><th>food_cost</th></tr></thead><tbody><tr><td>1</td><td>manish</td><td>arwal</td><td>india</td><td>N</td><td>2022-09-15</td><td>2022-09-25</td><td>77</td><td>1</td><td>manish</td><td>2023-03-11</td><td>bangalore</td><td>india</td><td>300</td></tr><tr><td>1</td><td>manish</td><td>arwal</td><td>india</td><td>N</td><td>2022-09-15</td><td>2022-09-25</td><td>1</td><td>1</td><td>manish</td><td>2023-01-16</td><td>gurgaon</td><td>india</td><td>380</td></tr><tr><td>2</td><td>vikash</td><td>patna</td><td>india</td><td>Y</td><td>2023-08-12</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>3</td><td>nikita</td><td>delhi</td><td>india</td><td>Y</td><td>2023-09-10</td><td>null</td><td>12</td><td>3</td><td>nikita</td><td>2023-09-20</td><td>delhi</td><td>india</td><td>127</td></tr><tr><td>4</td><td>rakesh</td><td>jaipur</td><td>india</td><td>Y</td><td>2023-06-10</td><td>null</td><td>54</td><td>4</td><td>rakesh</td><td>2023-08-10</td><td>jaipur</td><td>india</td><td>321</td></tr><tr><td>5</td><td>ayush</td><td>NY</td><td>USA</td><td>Y</td><td>2023-06-10</td><td>null</td><td>65</td><td>5</td><td>ayush</td><td>2023-09-07</td><td>mosco</td><td>russia</td><td>765</td></tr><tr><td>1</td><td>manish</td><td>gurgaon</td><td>india</td><td>Y</td><td>2022-09-25</td><td>null</td><td>77</td><td>1</td><td>manish</td><td>2023-03-11</td><td>bangalore</td><td>india</td><td>300</td></tr><tr><td>1</td><td>manish</td><td>gurgaon</td><td>india</td><td>Y</td><td>2022-09-25</td><td>null</td><td>1</td><td>1</td><td>manish</td><td>2023-01-16</td><td>gurgaon</td><td>india</td><td>380</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         1,
         "manish",
         "arwal",
         "india",
         "N",
         "2022-09-15",
         "2022-09-25",
         77,
         1,
         "manish",
         "2023-03-11",
         "bangalore",
         "india",
         300
        ],
        [
         1,
         "manish",
         "arwal",
         "india",
         "N",
         "2022-09-15",
         "2022-09-25",
         1,
         1,
         "manish",
         "2023-01-16",
         "gurgaon",
         "india",
         380
        ],
        [
         2,
         "vikash",
         "patna",
         "india",
         "Y",
         "2023-08-12",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         3,
         "nikita",
         "delhi",
         "india",
         "Y",
         "2023-09-10",
         null,
         12,
         3,
         "nikita",
         "2023-09-20",
         "delhi",
         "india",
         127
        ],
        [
         4,
         "rakesh",
         "jaipur",
         "india",
         "Y",
         "2023-06-10",
         null,
         54,
         4,
         "rakesh",
         "2023-08-10",
         "jaipur",
         "india",
         321
        ],
        [
         5,
         "ayush",
         "NY",
         "USA",
         "Y",
         "2023-06-10",
         null,
         65,
         5,
         "ayush",
         "2023-09-07",
         "mosco",
         "russia",
         765
        ],
        [
         1,
         "manish",
         "gurgaon",
         "india",
         "Y",
         "2022-09-25",
         null,
         77,
         1,
         "manish",
         "2023-03-11",
         "bangalore",
         "india",
         300
        ],
        [
         1,
         "manish",
         "gurgaon",
         "india",
         "Y",
         "2022-09-25",
         null,
         1,
         1,
         "manish",
         "2023-01-16",
         "gurgaon",
         "india",
         380
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "city",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "active",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "effective_start_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "effective_end_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sales_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "customer_id",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "customer_name",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "sales_date",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "food_delivery_address",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "food_delivery_country",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "food_cost",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "joined_data = customer_dim_df.join(sales_df, customer_dim_df[\"id\"]==sales_df[\"customer_id\"], \"left\")\n",
    "display(joined_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6b7ee7b1-8f31-4c41-956f-8224422140de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------+---------------------+------+--------------------+------------------+\n|customer_id|customer_name|     city|food_delivery_country|active|effective_start_date|effective_end_date|\n+-----------+-------------+---------+---------------------+------+--------------------+------------------+\n|          1|       manish|bangalore|                india|     Y|          2023-03-11|              null|\n|          5|        ayush|    mosco|               russia|     Y|          2023-09-07|              null|\n+-----------+-------------+---------+---------------------+------+--------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Handle update records Step 1 is to mark active\n",
    "new_record_df = joined_data.filter((col(\"food_delivery_address\") != col(\"city\")) & (col(\"active\") == \"Y\"))\\\n",
    "    .withColumn(\"active\", lit(\"Y\"))\\\n",
    "    .withColumn(\"effective_start_date\", col(\"sales_date\"))\\\n",
    "    .withColumn(\"effective_end_date\", lit(None))\\\n",
    "    .select(\"customer_id\", \"customer_name\", col(\"food_delivery_address\").alias(\"city\"), \"food_delivery_country\", \"active\", \"effective_start_date\", \"effective_end_date\")\n",
    "\n",
    "new_record_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04ed72d9-d073-491f-ab99-23b8a5700e38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------------+------+--------------------+------------------+\n|customer_id|customer_name|   city|food_delivery_country|active|effective_start_date|effective_end_date|\n+-----------+-------------+-------+---------------------+------+--------------------+------------------+\n|          1|       manish|gurgaon|                india|     N|          2022-09-25|        2023-03-11|\n|          5|        ayush|     NY|               russia|     N|          2023-06-10|        2023-09-07|\n+-----------+-------------+-------+---------------------+------+--------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Handle update records Step 2 is to mark existing records as inactive (active=N, and update effective_end_date)\n",
    "\n",
    "old_record_df = joined_data.filter((col(\"food_delivery_address\") != col(\"city\")) & (col(\"active\") == \"Y\"))\\\n",
    "    .withColumn(\"active\", lit(\"N\"))\\\n",
    "    .withColumn(\"effective_end_date\", col(\"sales_date\"))\\\n",
    "    .select(\"customer_id\", \"customer_name\", \"city\", \"food_delivery_country\", \"active\", \"effective_start_date\", \"effective_end_date\")\n",
    "\n",
    "old_record_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a8e29b0-6686-44ec-b6c0-b83b0d02e4f5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+---------------------+---------------------+------+--------------------+------------------+\n|customer_id|customer_name|food_delivery_address|food_delivery_country|active|effective_start_date|effective_end_date|\n+-----------+-------------+---------------------+---------------------+------+--------------------+------------------+\n|          6|        rajat|               jaipur|                india|     Y|          2023-08-10|              null|\n+-----------+-------------+---------------------+---------------------+------+--------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "# Handle new records \n",
    "\n",
    "new_customer_df = sales_df.join(customer_dim_df, sales_df[\"customer_id\"]==customer_dim_df[\"id\"], \"left_anti\")\\\n",
    "    .withColumn(\"active\", lit(\"Y\"))\\\n",
    "    .withColumn(\"effective_start_date\", col(\"sales_date\"))\\\n",
    "    .withColumn(\"effective_end_date\", lit(None))\\\n",
    "    .select(\"customer_id\", \"customer_name\", \"food_delivery_address\", \"food_delivery_country\", \"active\", \"effective_start_date\", \"effective_end_date\")\n",
    "\n",
    "new_customer_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0285b4c-a574-4ee6-acd2-be063bb7f2f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------+-------+------+--------------------+------------------+\n| id|  name|     city|country|active|effective_start_date|effective_end_date|\n+---+------+---------+-------+------+--------------------+------------------+\n|  1|manish|    arwal|  india|     N|          2022-09-15|        2022-09-25|\n|  2|vikash|    patna|  india|     Y|          2023-08-12|              null|\n|  3|nikita|    delhi|  india|     Y|          2023-09-10|              null|\n|  4|rakesh|   jaipur|  india|     Y|          2023-06-10|              null|\n|  5| ayush|       NY|    USA|     Y|          2023-06-10|              null|\n|  1|manish|  gurgaon|  india|     Y|          2022-09-25|              null|\n|  1|manish|bangalore|  india|     Y|          2023-03-11|              null|\n|  5| ayush|    mosco| russia|     Y|          2023-09-07|              null|\n|  1|manish|  gurgaon|  india|     N|          2022-09-25|        2023-03-11|\n|  5| ayush|       NY| russia|     N|          2023-06-10|        2023-09-07|\n|  6| rajat|   jaipur|  india|     Y|          2023-08-10|              null|\n+---+------+---------+-------+------+--------------------+------------------+\n\n"
     ]
    }
   ],
   "source": [
    "final_record_df = customer_dim_df.union(new_record_df).union(old_record_df).union(new_customer_df)\n",
    "\n",
    "final_record_df.show()\n",
    "\"\"\"\n",
    "|  1|manish|  gurgaon|  india|     Y|          2022-09-25|              null|\n",
    "|  1|manish|bangalore|  india|     Y|          2023-03-11|              null|\n",
    "How can Manish exists in 2 locations ?!\n",
    "Here drop unwanted records based on effective_start_date desc, keep latest row drop old rows\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1481979d-c4e0-4a3e-b073-0d628a18d081",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: long (nullable = true)\n |-- name: string (nullable = true)\n |-- city: string (nullable = true)\n |-- country: string (nullable = true)\n |-- active: string (nullable = true)\n |-- effective_start_date: date (nullable = true)\n |-- effective_end_date: string (nullable = true)\n |-- rn: integer (nullable = false)\n\n+---+------+---------+-------+------+--------------------+------------------+---+\n| id|  name|     city|country|active|effective_start_date|effective_end_date| rn|\n+---+------+---------+-------+------+--------------------+------------------+---+\n|  1|manish|  gurgaon|  india|     N|          2022-09-25|        2023-03-11|  1|\n|  1|manish|    arwal|  india|     N|          2022-09-15|        2022-09-25|  2|\n|  1|manish|bangalore|  india|     Y|          2023-03-11|              null|  1|\n|  2|vikash|    patna|  india|     Y|          2023-08-12|              null|  1|\n|  3|nikita|    delhi|  india|     Y|          2023-09-10|              null|  1|\n|  4|rakesh|   jaipur|  india|     Y|          2023-06-10|              null|  1|\n|  5| ayush|       NY| russia|     N|          2023-06-10|        2023-09-07|  1|\n|  5| ayush|    mosco| russia|     Y|          2023-09-07|              null|  1|\n|  6| rajat|   jaipur|  india|     Y|          2023-08-10|              null|  1|\n+---+------+---------+-------+------+--------------------+------------------+---+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import *\n",
    "\n",
    "# sorting wont happen correctly if type is string, cast to date first and then sort\n",
    "final_record_df.withColumn(\"effective_start_date\", col(\"effective_start_date\").cast(\"date\")).withColumn(\"rn\", row_number().over(Window.partitionBy(\"id\", \"active\").orderBy(desc(\"effective_start_date\")))).printSchema()\n",
    "\n",
    "\n",
    "final_record_df.withColumn(\"effective_start_date\", col(\"effective_start_date\").cast(\"date\")).withColumn(\"rn\", row_number().over(Window.partitionBy(\"id\", \"active\").orderBy(col(\"effective_start_date\").desc())))\\\n",
    "    .filter(~((col(\"rn\")>=2) & (col(\"active\")==\"Y\")))\\\n",
    "    .show()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "24 SCD 2 PySpark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
