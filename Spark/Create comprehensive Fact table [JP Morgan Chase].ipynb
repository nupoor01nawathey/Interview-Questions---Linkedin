{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb9234ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+\n",
      "|employee_id|department|salary|\n",
      "+-----------+----------+------+\n",
      "|1          |HR        |15000 |\n",
      "|2          |IT        |18000 |\n",
      "|3          |HR        |20000 |\n",
      "|4          |IT        |25000 |\n",
      "|5          |ADMIN     |12000 |\n",
      "+-----------+----------+------+\n",
      "\n",
      "root\n",
      " |-- employee_id: integer (nullable = false)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: integer (nullable = false)\n",
      "\n",
      "+-----------+----------+---------+----------+---------+-------+\n",
      "|employee_id|first_name|last_name|DOB       |state    |country|\n",
      "+-----------+----------+---------+----------+---------+-------+\n",
      "|1          |Rohit     |Khanna   |1995-12-10|Delhi    |IN     |\n",
      "|2          |Arjun     |Rao      |1993-10-10|Chennai  |IN     |\n",
      "|3          |Kuldeep   |Nair     |1994-02-20|Delhi    |IN     |\n",
      "|4          |Viraj     |Khaskar  |1995-03-19|Bengalore|IN     |\n",
      "|5          |Aditya    |Paul     |1996-06-12|Mumbai   |IN     |\n",
      "+-----------+----------+---------+----------+---------+-------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "employee_fact_df: org.apache.spark.sql.DataFrame = [employee_id: int, department: string ... 1 more field]\n",
       "person_dim_df: org.apache.spark.sql.DataFrame = [employee_id: int, first_name: string ... 4 more fields]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// This question was asked in JPMorgan Chase & Co. interview for Senior Data Engineer Role.\n",
    "\n",
    "// üìä Question: Create a Comprehensive Fact Table\n",
    "\n",
    "// ‚û° Given two input files:\n",
    "// üëâ employee.csv with columns: employee_id, department, salary\n",
    "// üëâ person.csv with columns: employee_id, first_name, last_name, DOB, state, country\n",
    "\n",
    "// ‚û° Write transformations to create employee_fact with columns:\n",
    "//  -- employee_id\n",
    "//  -- employee_full_name\n",
    "//  -- department\n",
    "//  -- salary\n",
    "//  -- Salary_Diff_to_reach_highest_sal (consider it to be Company's highest)\n",
    "// -- DOB\n",
    "// -- state\n",
    "// -- country\n",
    "// -- age\n",
    "\n",
    "// ‚úÖ ùóòùòÖùóΩùóπùóÆùóªùóÆùòÅùó∂ùóºùóª:\n",
    "// 1Ô∏è‚É£ Fetch the highest salary at company's level\n",
    "// 2Ô∏è‚É£ Join two files and prepare the required columns\n",
    "\n",
    "\n",
    "val employee_fact_df = Seq(\n",
    "    (1, \"HR\", 15000),\n",
    "    (2, \"IT\", 18000),\n",
    "    (3, \"HR\", 20000),\n",
    "    (4, \"IT\", 25000),\n",
    "    (5, \"ADMIN\", 12000)\n",
    ").toDF(\"employee_id\",\"department\",\"salary\")\n",
    "\n",
    "employee_fact_df.show(false)\n",
    "employee_fact_df.printSchema()\n",
    "\n",
    "val person_dim_df = Seq(\n",
    "    (1,\"Rohit\",\"Khanna\",\"1995-12-10\",\"Delhi\",\"IN\"),\n",
    "    (2,\"Arjun\",\"Rao\",\"1993-10-10\",\"Chennai\",\"IN\"),\n",
    "    (3,\"Kuldeep\",\"Nair\",\"1994-02-20\",\"Delhi\",\"IN\"),\n",
    "    (4,\"Viraj\",\"Khaskar\",\"1995-03-19\",\"Bengalore\",\"IN\"),\n",
    "    (5,\"Aditya\",\"Paul\",\"1996-06-12\",\"Mumbai\",\"IN\"),\n",
    ").toDF(\"employee_id\",\"first_name\",\"last_name\",\"DOB\",\"state\",\"country\")\n",
    "\n",
    "person_dim_df.show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0636abcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+----------+------+-------------------------------+----------+---------+-------+---+\n",
      "|employee_id|employee_full_name|department|salary|salary_diff_to_reach_max_salary|DOB       |state    |country|age|\n",
      "+-----------+------------------+----------+------+-------------------------------+----------+---------+-------+---+\n",
      "|1          |Rohit Khanna      |HR        |15000 |10000                          |1995-12-10|Delhi    |IN     |29 |\n",
      "|2          |Arjun Rao         |IT        |18000 |7000                           |1993-10-10|Chennai  |IN     |31 |\n",
      "|3          |Kuldeep Nair      |HR        |20000 |5000                           |1994-02-20|Delhi    |IN     |30 |\n",
      "|4          |Viraj Khaskar     |IT        |25000 |0                              |1995-03-19|Bengalore|IN     |29 |\n",
      "|5          |Aditya Paul       |ADMIN     |12000 |13000                          |1996-06-12|Mumbai   |IN     |28 |\n",
      "+-----------+------------------+----------+------+-------------------------------+----------+---------+-------+---+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\n",
       "result_df: org.apache.spark.sql.DataFrame = [employee_id: int, department: string ... 10 more fields]\n"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "val result_df = employee_fact_df.as(\"e\").join(person_dim_df.as(\"p\"), $\"e.employee_id\" === $\"p.employee_id\",\"inner\"\n",
    "    ).withColumn(\"employee_full_name\", concat_ws(\" \", $\"first_name\", $\"last_name\")\n",
    "    ).withColumn(\"max_salary\",  max($\"salary\").over()\n",
    "    ).withColumn(\"salary_diff_to_reach_max_salary\", $\"max_salary\" - $\"salary\"\n",
    "    ).withColumn(\"age\", year(current_date()) - year($\"DOB\")\n",
    "    ).drop($\"p.employee_id\")\n",
    "\n",
    "result_df.select(\"employee_id\",\"employee_full_name\",\"department\",\"salary\",\"salary_diff_to_reach_max_salary\",\n",
    "                \"DOB\",\"state\",\"country\",\"age\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a40535",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
