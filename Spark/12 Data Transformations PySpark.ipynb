{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0b7ba829-a4b5-4f6a-9aae-afffc4496b91",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+------+\n| id|    name|age|salary|address|gender|\n+---+--------+---+------+-------+------+\n|  1|  Manish| 26| 75000|  INDIA|     m|\n|  2|  Nikita| 23|100000|    USA|     f|\n|  3|  Pritam| 22|150000|  INDIA|     m|\n|  4|Prantosh| 17|200000|  JAPAN|     m|\n|  5|  Vikash| 31|300000|    USA|     m|\n|  6|   Rahul| 55|300000|  INDIA|     m|\n|  7|    Raju| 67|540000|    USA|     m|\n|  8| Praveen| 28| 70000|  JAPAN|     m|\n|  9|     Dev| 32|150000|  JAPAN|     m|\n| 10|  Sherin| 16| 25000| RUSSIA|     f|\n| 11|    Ragu| 12| 35000|  INDIA|     f|\n| 12|   Sweta| 43|200000|  INDIA|     f|\n| 13| Raushan| 48|650000|    USA|     m|\n| 14|  Mukesh| 36| 95000| RUSSIA|     m|\n| 15| Prakash| 52|750000|  INDIA|     m|\n+---+--------+---+------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "alias   filter/where    lit     add cols using withColumn    renaming cols using withColumnRenamed\n",
    "cast    drop columns\n",
    "\n",
    "NOTE: For each new transaformation stored in a df, Spark creates a new df as df is immutable \n",
    "USE DF API wisely or simply stick to spark.sql as both returns the same query plan in most of the cases(unless using udf)\n",
    "\"\"\"\n",
    "\n",
    "employee_df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .option(\"inferschema\", \"true\")\\\n",
    "    .load(\"/FileStore/tables/employee_write11_data.csv\")\n",
    "\n",
    "employee_df.show()\n",
    "employee_df.createOrReplaceTempView(\"employee_tbl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79045494-6f5f-4899-b41a-2535c4e7d575",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+\n|employee_id|age|\n+-----------+---+\n|          1| 26|\n|          2| 23|\n|          3| 22|\n|          4| 17|\n|          5| 31|\n+-----------+---+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "employee_df.select(col(\"id\").alias(\"employee_id\"), \"age\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3f9cada-a5ef-4846-90db-b466e316604c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+------+\n| id|    name|age|salary|address|gender|\n+---+--------+---+------+-------+------+\n|  4|Prantosh| 17|200000|  JAPAN|     m|\n+---+--------+---+------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.filter((col(\"salary\") > 150000) & (col(\"age\") < 18)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "97a1ed49-d5e0-45f3-a1ed-0adc4768dbb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+------+---------+\n| id|    name|age|salary|address|gender|last_name|\n+---+--------+---+------+-------+------+---------+\n|  1|  Manish| 26| 75000|  INDIA|     m|    kumar|\n|  2|  Nikita| 23|100000|    USA|     f|    kumar|\n|  3|  Pritam| 22|150000|  INDIA|     m|    kumar|\n|  4|Prantosh| 17|200000|  JAPAN|     m|    kumar|\n|  5|  Vikash| 31|300000|    USA|     m|    kumar|\n|  6|   Rahul| 55|300000|  INDIA|     m|    kumar|\n|  7|    Raju| 67|540000|    USA|     m|    kumar|\n|  8| Praveen| 28| 70000|  JAPAN|     m|    kumar|\n|  9|     Dev| 32|150000|  JAPAN|     m|    kumar|\n| 10|  Sherin| 16| 25000| RUSSIA|     f|    kumar|\n| 11|    Ragu| 12| 35000|  INDIA|     f|    kumar|\n| 12|   Sweta| 43|200000|  INDIA|     f|    kumar|\n| 13| Raushan| 48|650000|    USA|     m|    kumar|\n| 14|  Mukesh| 36| 95000| RUSSIA|     m|    kumar|\n| 15| Prakash| 52|750000|  INDIA|     m|    kumar|\n+---+--------+---+------+-------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.select(\"*\", lit(\"kumar\").alias(\"last_name\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6cc651c5-c092-42ff-aff5-e5b61abc85d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+---+------+-------+------+---------+\n| id|    name|age|salary|address|gender|last_name|\n+---+--------+---+------+-------+------+---------+\n|  1|  Manish| 26| 75000|  INDIA|     m|    singh|\n|  2|  Nikita| 23|100000|    USA|     f|    singh|\n|  3|  Pritam| 22|150000|  INDIA|     m|    singh|\n|  4|Prantosh| 17|200000|  JAPAN|     m|    singh|\n|  5|  Vikash| 31|300000|    USA|     m|    singh|\n|  6|   Rahul| 55|300000|  INDIA|     m|    singh|\n|  7|    Raju| 67|540000|    USA|     m|    singh|\n|  8| Praveen| 28| 70000|  JAPAN|     m|    singh|\n|  9|     Dev| 32|150000|  JAPAN|     m|    singh|\n| 10|  Sherin| 16| 25000| RUSSIA|     f|    singh|\n| 11|    Ragu| 12| 35000|  INDIA|     f|    singh|\n| 12|   Sweta| 43|200000|  INDIA|     f|    singh|\n| 13| Raushan| 48|650000|    USA|     m|    singh|\n| 14|  Mukesh| 36| 95000| RUSSIA|     m|    singh|\n| 15| Prakash| 52|750000|  INDIA|     m|    singh|\n+---+--------+---+------+-------+------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "# withColumn equivalent of employee_df.select(\"*\", lit(\"kumar\").alias(\"last_name\")).show()\n",
    "\n",
    "employee_df.withColumn(\"last_name\", lit(\"singh\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3819c81-ae1f-4c50-8582-43c6a2786862",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+---+------+-------+------+\n|employee_id|    name|age|salary|address|gender|\n+-----------+--------+---+------+-------+------+\n|          1|  Manish| 26| 75000|  INDIA|     m|\n|          2|  Nikita| 23|100000|    USA|     f|\n|          3|  Pritam| 22|150000|  INDIA|     m|\n|          4|Prantosh| 17|200000|  JAPAN|     m|\n|          5|  Vikash| 31|300000|    USA|     m|\n|          6|   Rahul| 55|300000|  INDIA|     m|\n|          7|    Raju| 67|540000|    USA|     m|\n|          8| Praveen| 28| 70000|  JAPAN|     m|\n|          9|     Dev| 32|150000|  JAPAN|     m|\n|         10|  Sherin| 16| 25000| RUSSIA|     f|\n|         11|    Ragu| 12| 35000|  INDIA|     f|\n|         12|   Sweta| 43|200000|  INDIA|     f|\n|         13| Raushan| 48|650000|    USA|     m|\n|         14|  Mukesh| 36| 95000| RUSSIA|     m|\n|         15| Prakash| 52|750000|  INDIA|     m|\n+-----------+--------+---+------+-------+------+\n\n"
     ]
    }
   ],
   "source": [
    "new_employee_df = employee_df.withColumnRenamed(\"id\", \"employee_id\")\n",
    "new_employee_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aae887e3-71fd-4e51-ae97-540e39507804",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- id: string (nullable = true)\n |-- name: string (nullable = true)\n |-- age: integer (nullable = true)\n |-- salary: long (nullable = true)\n |-- address: string (nullable = true)\n |-- gender: string (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.withColumn(\"id\", col(\"id\").cast(\"string\"))\\\n",
    "    .withColumn(\"salary\", col(\"salary\").cast(\"long\"))\\\n",
    "    .printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88311269-c0b6-4383-b125-6970aca0863a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-------+------+\n|age|salary|address|gender|\n+---+------+-------+------+\n| 26| 75000|  INDIA|     m|\n| 23|100000|    USA|     f|\n| 22|150000|  INDIA|     m|\n| 17|200000|  JAPAN|     m|\n| 31|300000|    USA|     m|\n+---+------+-------+------+\nonly showing top 5 rows\n\n"
     ]
    }
   ],
   "source": [
    "employee_df.drop(\"id\", col(\"name\")).show(5)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "12 Data Transformations PySpark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}