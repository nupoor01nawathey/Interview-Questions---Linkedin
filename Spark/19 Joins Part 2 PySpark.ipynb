{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45042569-a491-4ada-beae-4587f96802ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+\n|customer_id|customer_name|address|date_of_joining|\n+-----------+-------------+-------+---------------+\n|          1|       manish|  patna|     30-05-2022|\n|          2|       vikash|kolkata|     12-03-2023|\n|          3|       nikita|  delhi|     25-06-2023|\n|          4|        rahul| ranchi|     24-03-2023|\n|          5|       mahesh| jaipur|     22-03-2023|\n|          6|     prantosh|kolkata|     18-10-2022|\n|          7|        raman|  patna|     30-12-2022|\n|          8|      prakash| ranchi|     24-02-2023|\n|          9|       ragini|kolkata|     03-03-2023|\n|         10|      raushan| jaipur|     05-02-2023|\n+-----------+-------------+-------+---------------+\n\n+-----------+----------+--------+----------------+\n|customer_id|product_id|quantity|date_of_purchase|\n+-----------+----------+--------+----------------+\n|          1|        22|      10|      01-06-2022|\n|          1|        27|       5|      03-02-2023|\n|          2|         5|       3|      01-06-2023|\n|          5|        22|       1|      22-03-2023|\n|          7|        22|       4|      03-02-2023|\n|          9|         5|       6|      03-03-2023|\n|          2|         1|      12|      15-06-2023|\n|          1|        56|       2|      25-06-2023|\n|          5|        12|       5|      15-04-2023|\n|         11|        12|      76|      12-03-2023|\n+-----------+----------+--------+----------------+\n\n+---+-------+-----+\n| id|   name|price|\n+---+-------+-----+\n|  1|  fanta|   20|\n|  2|    dew|   22|\n|  5| sprite|   40|\n|  7|redbull|  100|\n| 12|  mazza|   45|\n| 22|   coke|   27|\n| 25|  limca|   21|\n| 27|  pepsi|   14|\n| 56|  sting|   10|\n+---+-------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "customer_data = [(1,'manish','patna',\"30-05-2022\"),\n",
    "(2,'vikash','kolkata',\"12-03-2023\"),\n",
    "(3,'nikita','delhi',\"25-06-2023\"),\n",
    "(4,'rahul','ranchi',\"24-03-2023\"),\n",
    "(5,'mahesh','jaipur',\"22-03-2023\"),\n",
    "(6,'prantosh','kolkata',\"18-10-2022\"),\n",
    "(7,'raman','patna',\"30-12-2022\"),\n",
    "(8,'prakash','ranchi',\"24-02-2023\"),\n",
    "(9,'ragini','kolkata',\"03-03-2023\"),\n",
    "(10,'raushan','jaipur',\"05-02-2023\")]\n",
    "\n",
    "customer_schema=['customer_id','customer_name','address','date_of_joining']\n",
    "\n",
    "\n",
    "sales_data = [(1,22,10,\"01-06-2022\"),\n",
    "(1,27,5,\"03-02-2023\"),\n",
    "(2,5,3,\"01-06-2023\"),\n",
    "(5,22,1,\"22-03-2023\"),\n",
    "(7,22,4,\"03-02-2023\"),\n",
    "(9,5,6,\"03-03-2023\"),\n",
    "(2,1,12,\"15-06-2023\"),\n",
    "(1,56,2,\"25-06-2023\"),\n",
    "(5,12,5,\"15-04-2023\"),\n",
    "(11,12,76,\"12-03-2023\")]\n",
    "\n",
    "sales_schema=['customer_id','product_id','quantity','date_of_purchase']\n",
    "\n",
    "\n",
    "product_data = [(1, 'fanta',20),\n",
    "(2, 'dew',22),\n",
    "(5, 'sprite',40),\n",
    "(7, 'redbull',100),\n",
    "(12,'mazza',45),\n",
    "(22,'coke',27),\n",
    "(25,'limca',21),\n",
    "(27,'pepsi',14),\n",
    "(56,'sting',10)]\n",
    "\n",
    "product_schema=['id','name','price']\n",
    "\n",
    "customer_df = spark.createDataFrame(data=customer_data, schema=customer_schema)\n",
    "sales_df = spark.createDataFrame(data=sales_data, schema=sales_schema)\n",
    "product_df = spark.createDataFrame(data=product_data, schema=product_schema)\n",
    "\n",
    "\n",
    "customer_df.show()\n",
    "sales_df.show()\n",
    "product_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15c916f5-ef70-441d-b65d-4ee9c5f29247",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|customer_id|customer_name|address|date_of_joining|customer_id|product_id|quantity|date_of_purchase|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n|          1|       manish|  patna|     30-05-2022|          1|        56|       2|      25-06-2023|\n|          1|       manish|  patna|     30-05-2022|          1|        27|       5|      03-02-2023|\n|          1|       manish|  patna|     30-05-2022|          1|        22|      10|      01-06-2022|\n|          2|       vikash|kolkata|     12-03-2023|          2|         1|      12|      15-06-2023|\n|          2|       vikash|kolkata|     12-03-2023|          2|         5|       3|      01-06-2023|\n|          3|       nikita|  delhi|     25-06-2023|       null|      null|    null|            null|\n|          4|        rahul| ranchi|     24-03-2023|       null|      null|    null|            null|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        12|       5|      15-04-2023|\n|          5|       mahesh| jaipur|     22-03-2023|          5|        22|       1|      22-03-2023|\n|          6|     prantosh|kolkata|     18-10-2022|       null|      null|    null|            null|\n|          7|        raman|  patna|     30-12-2022|          7|        22|       4|      03-02-2023|\n|          8|      prakash| ranchi|     24-02-2023|       null|      null|    null|            null|\n|          9|       ragini|kolkata|     03-03-2023|          9|         5|       6|      03-03-2023|\n|         10|      raushan| jaipur|     05-02-2023|       null|      null|    null|            null|\n+-----------+-------------+-------+---------------+-----------+----------+--------+----------------+\n\nOut[4]: 14"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "\"\"\"\n",
    "left: entire left table + matching from right table\n",
    "\"\"\"\n",
    "customer_df.join(sales_df, customer_df[\"customer_id\"]==sales_df[\"customer_id\"], \"left\").show()\n",
    "customer_df.join(sales_df, customer_df[\"customer_id\"]==sales_df[\"customer_id\"], \"left\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05484bc9-c458-4b82-bbe8-c8996c7df998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+----------------+---+-------+-----+\n|customer_id|product_id|quantity|date_of_purchase| id|   name|price|\n+-----------+----------+--------+----------------+---+-------+-----+\n|          1|        56|       2|      25-06-2023|  1|  fanta|   20|\n|          1|        27|       5|      03-02-2023|  1|  fanta|   20|\n|          1|        22|      10|      01-06-2022|  1|  fanta|   20|\n|          2|         1|      12|      15-06-2023|  2|    dew|   22|\n|          2|         5|       3|      01-06-2023|  2|    dew|   22|\n|          5|        12|       5|      15-04-2023|  5| sprite|   40|\n|          5|        22|       1|      22-03-2023|  5| sprite|   40|\n|          7|        22|       4|      03-02-2023|  7|redbull|  100|\n|       null|      null|    null|            null| 12|  mazza|   45|\n|       null|      null|    null|            null| 22|   coke|   27|\n|       null|      null|    null|            null| 25|  limca|   21|\n|       null|      null|    null|            null| 27|  pepsi|   14|\n|       null|      null|    null|            null| 56|  sting|   10|\n+-----------+----------+--------+----------------+---+-------+-----+\n\nOut[9]: 13"
     ]
    }
   ],
   "source": [
    "\n",
    "sales_df.join(product_df, sales_df[\"customer_id\"]==product_df[\"id\"], \"right\").show()\n",
    "sales_df.join(product_df, sales_df[\"customer_id\"]==product_df[\"id\"], \"right\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ace23219-ec67-41ed-b0f7-abc29cbe6b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+--------+----------------+----+-------+-----+\n|customer_id|product_id|quantity|date_of_purchase|  id|   name|price|\n+-----------+----------+--------+----------------+----+-------+-----+\n|          1|        22|      10|      01-06-2022|   1|  fanta|   20|\n|          1|        27|       5|      03-02-2023|   1|  fanta|   20|\n|          1|        56|       2|      25-06-2023|   1|  fanta|   20|\n|          2|         5|       3|      01-06-2023|   2|    dew|   22|\n|          2|         1|      12|      15-06-2023|   2|    dew|   22|\n|          5|        22|       1|      22-03-2023|   5| sprite|   40|\n|          5|        12|       5|      15-04-2023|   5| sprite|   40|\n|          7|        22|       4|      03-02-2023|   7|redbull|  100|\n|          9|         5|       6|      03-03-2023|null|   null| null|\n|         11|        12|      76|      12-03-2023|null|   null| null|\n|       null|      null|    null|            null|  12|  mazza|   45|\n|       null|      null|    null|            null|  22|   coke|   27|\n|       null|      null|    null|            null|  25|  limca|   21|\n|       null|      null|    null|            null|  27|  pepsi|   14|\n|       null|      null|    null|            null|  56|  sting|   10|\n+-----------+----------+--------+----------------+----+-------+-----+\n\nOut[10]: 15"
     ]
    }
   ],
   "source": [
    "sales_df.join(product_df, sales_df[\"customer_id\"]==product_df[\"id\"], \"outer\").show()\n",
    "sales_df.join(product_df, sales_df[\"customer_id\"]==product_df[\"id\"], \"outer\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2eb67af2-99f5-45c1-9604-c62378c3a132",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+\n|customer_id|customer_name|address|date_of_joining|\n+-----------+-------------+-------+---------------+\n|          1|       manish|  patna|     30-05-2022|\n|          2|       vikash|kolkata|     12-03-2023|\n|          5|       mahesh| jaipur|     22-03-2023|\n|          7|        raman|  patna|     30-12-2022|\n|          9|       ragini|kolkata|     03-03-2023|\n+-----------+-------------+-------+---------------+\n\nOut[11]: 5"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "left_semi: extract cols only from left table where left table has matching data with right table\n",
    "inner join between left + right and then pick only left table cols\n",
    "\"\"\"\n",
    "customer_df.join(sales_df, customer_df[\"customer_id\"]==sales_df[\"customer_id\"], \"left_semi\").show()\n",
    "customer_df.join(sales_df, customer_df[\"customer_id\"]==sales_df[\"customer_id\"], \"left_semi\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d8f29bc-ff26-4fba-b944-69fdf38472ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+---------------+\n|customer_id|customer_name|address|date_of_joining|\n+-----------+-------------+-------+---------------+\n|          3|       nikita|  delhi|     25-06-2023|\n|          4|        rahul| ranchi|     24-03-2023|\n|          6|     prantosh|kolkata|     18-10-2022|\n|          8|      prakash| ranchi|     24-02-2023|\n|         10|      raushan| jaipur|     05-02-2023|\n+-----------+-------------+-------+---------------+\n\nOut[13]: 5"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "left_anti: only left table cols which don't join with right table\n",
    "uncommon rec from right table\n",
    "commonly used to identify NEW rows in SCD 1 / 2\n",
    "\"\"\"\n",
    "customer_df.join(sales_df, customer_df[\"customer_id\"]==sales_df[\"customer_id\"], \"left_anti\").show()\n",
    "customer_df.join(sales_df, customer_df[\"customer_id\"]==sales_df[\"customer_id\"], \"left_anti\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a04cea95-6040-4d02-904d-28e7a3e80aa0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[14]: 100"
     ]
    }
   ],
   "source": [
    "customer_df.crossJoin(sales_df).count() # use with caution, expensive join type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2341835-befc-4962-bf0b-53f0cbc7cdab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+---------+\n|personId|lastName|firstName|\n+--------+--------+---------+\n|       1|    Wang|    Allen|\n|       2|   Alice|      Bob|\n+--------+--------+---------+\n\n+---------+--------+-------------+----------+\n|addressId|personId|         city|     state|\n+---------+--------+-------------+----------+\n|        1|       2|New York City|  New York|\n|        2|       3|     Leetcode|California|\n+---------+--------+-------------+----------+\n\n+---------+--------+-------------+--------+\n|firstName|lastName|         city|   state|\n+---------+--------+-------------+--------+\n|    Allen|    Wang|         null|    null|\n|      Bob|   Alice|New York City|New York|\n+---------+--------+-------------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "LC 175. Combine Two Tables\n",
    "Write a solution to report the first name, last name, city, and state of each person in the Person table. If the address of a personId is not present in the Address table, report null instead. Return the result table in any order.\n",
    "\n",
    "Input: \n",
    "Person table:\n",
    "+----------+----------+-----------+\n",
    "| personId | lastName | firstName |\n",
    "+----------+----------+-----------+\n",
    "| 1        | Wang     | Allen     |\n",
    "| 2        | Alice    | Bob       |\n",
    "+----------+----------+-----------+\n",
    "Address table:\n",
    "+-----------+----------+---------------+------------+\n",
    "| addressId | personId | city          | state      |\n",
    "+-----------+----------+---------------+------------+\n",
    "| 1         | 2        | New York City | New York   |\n",
    "| 2         | 3        | Leetcode      | California |\n",
    "+-----------+----------+---------------+------------+\n",
    "Output: \n",
    "+-----------+----------+---------------+----------+\n",
    "| firstName | lastName | city          | state    |\n",
    "+-----------+----------+---------------+----------+\n",
    "| Allen     | Wang     | Null          | Null     |\n",
    "| Bob       | Alice    | New York City | New York |\n",
    "+-----------+----------+---------------+----------+\n",
    "Explanation: \n",
    "There is no address in the address table for the personId = 1 so we return null in their city and state.\n",
    "addressId = 1 contains information about the address of personId = 2.\n",
    "\n",
    "Person table:\n",
    "+----------+----------+-----------+\n",
    "| personId | lastName | firstName |\n",
    "+----------+----------+-----------+\n",
    "| 1        | Wang     | Allen     |\n",
    "| 2        | Alice    | Bob       |\n",
    "+----------+----------+-----------+\n",
    "Address table:\n",
    "+-----------+----------+---------------+------------+\n",
    "| addressId | personId | city          | state      |\n",
    "+-----------+----------+---------------+------------+\n",
    "| 1         | 2        | New York City | New York   |\n",
    "| 2         | 3        | Leetcode      | California |\n",
    "+-----------+----------+---------------+------------+\n",
    "\"\"\"\n",
    "\n",
    "person_df = spark.createDataFrame(\n",
    "    [\n",
    "        (1, \"Wang\", \"Allen\"),\n",
    "        (2, \"Alice\", \"Bob\")\n",
    "    ], [\"personId\", \"lastName\", \"firstName\"]\n",
    ")\n",
    "\n",
    "address_df = spark.createDataFrame(\n",
    "    [\n",
    "        (1, 2, \"New York City\", \"New York\"),\n",
    "        (2, 3, \"Leetcode\", \"California\")\n",
    "    ],\n",
    "    [\"addressId\", \"personId\", \"city\", \"state\"]\n",
    ")\n",
    "\n",
    "person_df.show()\n",
    "address_df.show()\n",
    "\n",
    "person_df.join(address_df, person_df[\"personId\"]==address_df[\"personId\"], \"left\")\\\n",
    "    .select(\"firstName\", \"lastName\", \"city\", \"state\")\\\n",
    "    .show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "19 Joins Part 2 PySpark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}