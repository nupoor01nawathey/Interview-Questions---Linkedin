{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14f5aac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://192.168.0.102:4040\n",
       "SparkContext available as 'sc' (version = 3.4.1, master = local[*], app id = local-1705076977783)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+--------+\n",
      "|ORDERID|ORDER_DATE|PRODUCT_PRICE|QUANTITY|\n",
      "+-------+----------+-------------+--------+\n",
      "|O1     |2023-01-01|300          |2       |\n",
      "|O2     |2022-01-01|200          |5       |\n",
      "|O3     |2023-02-03|600          |5       |\n",
      "+-------+----------+-------------+--------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "df: org.apache.spark.sql.DataFrame = [ORDERID: string, ORDER_DATE: string ... 2 more fields]\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Write a query to get the total sales of the company and sales of the company for the current year.\n",
    "\n",
    "// Expected O/P :\n",
    "// ORDERID | ORDER_DATE | PRODUCT_PRICE | QUANTITY  | TOTAL_SALES | TOTAL_SALES_OF_YEAR\n",
    "// --------|------------|---------------|-----------|-------------|-----------------------\n",
    "// O1      | 2023-01-01 | 300           | 2         | 4600        | 3600\n",
    "// O2      | 2022-01-01 | 200           | 5         | 4600        | 3600\n",
    "// O3      | 2023-02-03 | 600           | 5         | 4600        | 3600\n",
    "\n",
    "\n",
    "val df = Seq(\n",
    "    (\"O1\",\"2023-01-01\",300,2),\n",
    "    (\"O2\",\"2022-01-01\",200,5),\n",
    "    (\"O3\",\"2023-02-03\",600,5),\n",
    ").toDF(\"ORDERID\",\"ORDER_DATE\",\"PRODUCT_PRICE\",\"QUANTITY\")\n",
    "\n",
    "df.show(false)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61da4587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+--------+----------+-----------+--------------------+\n",
      "|ORDERID|ORDER_DATE|PRODUCT_PRICE|QUANTITY|ORDER_DATE|total_sales|total_sale_prev_year|\n",
      "+-------+----------+-------------+--------+----------+-----------+--------------------+\n",
      "|O1     |2023-01-01|300          |2       |2023-01-01|4600       |3600                |\n",
      "|O2     |2022-01-01|200          |5       |2022-01-01|4600       |3600                |\n",
      "|O3     |2023-02-03|600          |5       |2023-02-03|4600       |3600                |\n",
      "+-------+----------+-------------+--------+----------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "// SPARK SQL \n",
    "// TRICK is to use window function without anything in the over(), this way there's no need to use any col for agg unlike group by\n",
    "\n",
    "df.createOrReplaceTempView(\"sales\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "    with years as (\n",
    "        select\n",
    "            *,\n",
    "            extract(year from to_date(ORDER_DATE)) as sale_year,\n",
    "            year(CURDATE())-1 as current_year\n",
    "        from sales\n",
    "    )\n",
    "    select \n",
    "        ORDERID,ORDER_DATE,PRODUCT_PRICE,QUANTITY,ORDER_DATE,\n",
    "        sum(PRODUCT_PRICE * QUANTITY) over() as total_sales,\n",
    "        sum(case when sale_year=current_year then product_price * quantity else 0 end) over() as total_sale_prev_year\n",
    "    from years\n",
    "\"\"\").show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b42aaefe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-------------+--------+-----------+--------------------+\n",
      "|ORDERID|ORDER_DATE|PRODUCT_PRICE|QUANTITY|total_sales|total_sale_prev_year|\n",
      "+-------+----------+-------------+--------+-----------+--------------------+\n",
      "|O1     |2023-01-01|300          |2       |4600       |3600.0              |\n",
      "|O2     |2022-01-01|200          |5       |4600       |3600.0              |\n",
      "|O3     |2023-02-03|600          |5       |4600       |3600.0              |\n",
      "+-------+----------+-------------+--------+-----------+--------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.expressions.Window\n",
       "window_spec: org.apache.spark.sql.expressions.WindowSpec = org.apache.spark.sql.expressions.WindowSpec@1bbccca\n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.expressions.Window\n",
    "\n",
    "val window_spec = Window.rowsBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "\n",
    "df.withColumn(\"ORDER_DATE\", $\"ORDER_DATE\".cast(\"date\")\n",
    "  ).withColumn(\"total_sales\", sum($\"PRODUCT_PRICE\" * $\"QUANTITY\").over(window_spec)\n",
    "  ).withColumn(\"total_sale_prev_year\", \n",
    "    sum(when(year($\"ORDER_DATE\") === year(current_date())-1, $\"PRODUCT_PRICE\" * $\"QUANTITY\"\n",
    "            ).otherwise(lit(\"0\"))).over(window_spec)).show(false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6affd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
