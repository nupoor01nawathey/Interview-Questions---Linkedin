{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae5c0eeb-e66e-4d92-9d6b-c56ad72dd5b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+\n| id|    name|salary|     dept|gender|\n+---+--------+------+---------+------+\n|  1|  manish| 50000|       IT|     m|\n|  2|  vikash| 60000|    sales|     m|\n|  3| raushan| 70000|marketing|     m|\n|  4|  mukesh| 80000|       IT|     m|\n|  5|   priti| 90000|    sales|     f|\n|  6|  nikita| 45000|marketing|     f|\n|  7|  ragini| 55000|marketing|     f|\n|  8|   rashi|100000|       IT|     f|\n|  9|  aditya| 65000|       IT|     m|\n| 10|   rahul| 50000|marketing|     m|\n| 11|   rakhi| 50000|       IT|     f|\n| 12|akhilesh| 90000|    sales|     m|\n+---+--------+------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "emp_df = spark.createDataFrame(\n",
    "    [\n",
    "        (1,'manish',50000,'IT','m'),\n",
    "        (2,'vikash',60000,'sales','m'),\n",
    "        (3,'raushan',70000,'marketing','m'),\n",
    "        (4,'mukesh',80000,'IT','m'),\n",
    "        (5,'priti',90000,'sales','f'),\n",
    "        (6,'nikita',45000,'marketing','f'),\n",
    "        (7,'ragini',55000,'marketing','f'),\n",
    "        (8,'rashi',100000,'IT','f'),\n",
    "        (9,'aditya',65000,'IT','m'),\n",
    "        (10,'rahul',50000,'marketing','m'),\n",
    "        (11,'rakhi',50000,'IT','f'),\n",
    "        (12,'akhilesh',90000,'sales','m')\n",
    "    ], [\"id\", \"name\", \"salary\", \"dept\", \"gender\"]\n",
    ")\n",
    "\n",
    "emp_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c73f285-5d98-4586-b49f-b3430ff0519f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+---+---+---+\n|id |name    |salary|dept     |gender|rn |rnk|dr |\n+---+--------+------+---------+------+---+---+---+\n|1  |manish  |50000 |IT       |m     |1  |1  |1  |\n|11 |rakhi   |50000 |IT       |f     |2  |1  |1  |\n|9  |aditya  |65000 |IT       |m     |3  |3  |2  |\n|4  |mukesh  |80000 |IT       |m     |4  |4  |3  |\n|8  |rashi   |100000|IT       |f     |5  |5  |4  |\n|6  |nikita  |45000 |marketing|f     |1  |1  |1  |\n|10 |rahul   |50000 |marketing|m     |2  |2  |2  |\n|7  |ragini  |55000 |marketing|f     |3  |3  |3  |\n|3  |raushan |70000 |marketing|m     |4  |4  |4  |\n|2  |vikash  |60000 |sales    |m     |1  |1  |1  |\n|5  |priti   |90000 |sales    |f     |2  |2  |2  |\n|12 |akhilesh|90000 |sales    |m     |3  |2  |2  |\n+---+--------+------+---------+------+---+---+---+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "window = Window.partitionBy(\"dept\").orderBy(\"salary\")\n",
    "\n",
    "emp_df.withColumn(\"rn\", row_number().over(window))\\\n",
    "    .withColumn(\"rnk\", rank().over(window))\\\n",
    "    .withColumn(\"dr\", dense_rank().over(window))\\\n",
    "    .show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08ec325f-6658-45ca-86c5-4805bec11b12",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+------+---------+------+\n| id|    name|salary|     dept|gender|\n+---+--------+------+---------+------+\n|  8|   rashi|100000|       IT|     f|\n|  4|  mukesh| 80000|       IT|     m|\n|  3| raushan| 70000|marketing|     m|\n|  7|  ragini| 55000|marketing|     f|\n|  5|   priti| 90000|    sales|     f|\n| 12|akhilesh| 90000|    sales|     m|\n|  2|  vikash| 60000|    sales|     m|\n+---+--------+------+---------+------+\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Calculate top 2 earner from each dept\n",
    "With dense_rank() for this particular example there will be 3 rows returned for sales dept\n",
    "\"\"\"\n",
    "emp_df.withColumn(\"dr\", dense_rank().over(Window.partitionBy(\"dept\").orderBy(desc(\"salary\"))))\\\n",
    "    .filter(col(\"dr\") <= 2).drop(\"dr\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "1"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "20 Window Functions PySpark",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}