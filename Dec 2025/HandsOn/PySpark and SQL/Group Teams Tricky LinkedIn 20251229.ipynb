{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8c5d0bc7-40e2-4d64-bd3c-006bf541e2b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+\n|emp_name|         city|\n+--------+-------------+\n|     Sam|     New York|\n|   David|     New York|\n|   Peter|     New York|\n|   Chris|     New York|\n|    John|     New York|\n|   Steve|San Francisco|\n|  Rachel|San Francisco|\n|  Robert|  Los Angeles|\n+--------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Write a query to return list of teams.\n",
    "\n",
    "Teams are formed using following rules:\n",
    "1. Team members must live in the city they represent.\n",
    "2. For each city, create teams of 3 until there are fewer than 3 who are unassigned.\n",
    "3. When there are fewer than 3 unassigned, create a team.\n",
    "\n",
    "Report requirements:\n",
    "1. City should be ordered alphabetically\n",
    "2. Players must be selected in the order that they appear\n",
    "3. Their names should appear alphabetically ordered within the comma separated list\n",
    "4. team_name column should concat \"Team\" and a row number in which they appear in the output\n",
    "s\n",
    "\n",
    "Input\n",
    "+--------+-------------+\n",
    "|emp_name|         city|\n",
    "+--------+-------------+\n",
    "|     Sam|     New York|\n",
    "|   David|     New York|\n",
    "|   Peter|     New York|\n",
    "|   Chris|     New York|\n",
    "|    John|     New York|\n",
    "|   Steve|San Francisco|\n",
    "|  Rachel|San Francisco|\n",
    "|  Robert|  Los Angeles|\n",
    "+--------+-------------+\n",
    "\n",
    "Output\n",
    "+-------------+---------------+---------+\n",
    "|         city|           team|team_name|\n",
    "+-------------+---------------+---------+\n",
    "|  Los Angeles|         Robert|    Team1|\n",
    "|     New York|David,Peter,Sam|    Team2|\n",
    "|     New York|     Chris,John|    Team3|\n",
    "|San Francisco|   Rachel,Steve|    Team4|\n",
    "+-------------+---------------+---------+\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "emp_details_df = spark.createDataFrame([\n",
    "    ('Sam', 'New York'),\n",
    "    ('David', 'New York'),\n",
    "    ('Peter', 'New York'),\n",
    "    ('Chris', 'New York'),\n",
    "    ('John', 'New York'),\n",
    "    ('Steve', 'San Francisco'),\n",
    "    ('Rachel', 'San Francisco'),\n",
    "    ('Robert', 'Los Angeles')\n",
    "], [\"emp_name\", \"city\"]\n",
    ")\n",
    "\n",
    "emp_details_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16d7deb2-7825-4147-b47e-b8b2a4c0d90e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/pyspark/sql/connect/expressions.py:1134: UserWarning: WARN WindowExpression: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------+\n|         city|           team|team_name|\n+-------------+---------------+---------+\n|  Los Angeles|         Robert|    Team1|\n|     New York|David,Peter,Sam|    Team2|\n|     New York|     Chris,John|    Team3|\n|San Francisco|   Rachel,Steve|    Team4|\n+-------------+---------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "emp_details_df \\\n",
    "    .withColumn(\"rn\", F.row_number().over(Window.partitionBy(F.col(\"city\")).orderBy(F.col(\"city\")))) \\\n",
    "    .withColumn(\"city_grp\", F.ceil(F.col(\"rn\")/3.0)) \\\n",
    "    .groupBy(\"city\", \"city_grp\").agg(\n",
    "        F.concat_ws(\",\", F.sort_array(F.collect_list(\"emp_name\"))).alias(\"team\")\n",
    "    ) \\\n",
    "    .withColumn(\"team_name\", F.concat(F.lit('Team'), F.row_number().over(Window.orderBy(F.col(\"city\"))))) \\\n",
    "    .drop(\"city_grp\") \\\n",
    "    .show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd8392e9-1783-4641-b997-cad1b750acb6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca9e2813-ad92-4c17-8133-df668df6d3bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+---------------+---------+\n|         city|           team|team_name|\n+-------------+---------------+---------+\n|  Los Angeles|         Robert|    Team1|\n|     New York|David,Peter,Sam|    Team2|\n|     New York|     Chris,John|    Team3|\n|San Francisco|   Rachel,Steve|    Team4|\n+-------------+---------------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "emp_details_df.createOrReplaceTempView(\"emp_details\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "          with cte as (\n",
    "            select \n",
    "                *, row_number() over(partition by city order by city) as rn\n",
    "            from emp_details\n",
    "          ), cte2 as (\n",
    "            select\n",
    "                *, ceiling(rn/3.0) as city_grp      \n",
    "            from cte \n",
    "          ), cte3 as (\n",
    "            select \n",
    "                city, city_grp, string_agg(emp_name, ',') within group(order by emp_name) as team\n",
    "            from cte2\n",
    "            group by city, city_grp\n",
    "          )\n",
    "          select\n",
    "            city, team, concat('Team', row_number() over(order by city)) as team_name\n",
    "          from cte3\n",
    "          \"\"\").show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Group Teams Tricky LinkedIn 20251229",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}