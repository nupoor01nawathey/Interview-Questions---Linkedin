{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a8e8b834-70d6-4008-ae8f-c1842dc16c58",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+-----+\n|product_id|price_date|price|\n+----------+----------+-----+\n|       100|2024-01-01|  150|\n|       100|2024-01-21|  170|\n|       100|2024-02-01|  190|\n|       101|2024-01-01| 1000|\n|       101|2024-01-27| 1200|\n|       101|2024-02-05| 1250|\n|       102|2024-01-01|   50|\n|       102|2024-01-15|   60|\n|       102|2024-02-01|   80|\n|       103|2024-01-01|  200|\n|       103|2024-01-18|  230|\n|       104|2024-01-03|  500|\n|       104|2024-02-01|  550|\n|       105|2024-01-10|  300|\n|       106|2024-01-05|  120|\n|       106|2024-01-25|  140|\n|       107|2024-02-01|  900|\n|       108|2024-01-04|  160|\n|       108|2024-02-06|  190|\n|       109|2024-01-02|   40|\n+----------+----------+-----+\n\n+--------+----------+----------+\n|order_id|order_date|product_id|\n+--------+----------+----------+\n|       1|2024-01-05|       100|\n|       2|2024-01-21|       100|\n|       3|2024-02-20|       100|\n|       4|2024-01-07|       101|\n|       5|2024-02-04|       101|\n|       6|2024-02-05|       101|\n|       7|2024-02-10|       101|\n|       8|2024-01-02|       102|\n|       9|2024-01-16|       102|\n|      10|2024-02-10|       102|\n|      11|2024-01-10|       103|\n|      12|2024-01-25|       103|\n|      13|2024-01-20|       104|\n|      14|2024-02-03|       105|\n|      15|2024-01-06|       106|\n|      16|2024-01-28|       106|\n|      17|2024-02-05|       107|\n|      18|2024-02-08|       108|\n|      19|2024-01-03|       109|\n|      20|2024-01-15|       109|\n+--------+----------+----------+\n\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "You are given a products table where a new row is inserted every time the price of a product changes. Additionally, there is a transaction table containing details such as order_date and product_id for each order.\n",
    "\n",
    "Write an SQL query to calculate the total sales value for each product, considering the cost of the product at the time of the order date, display the output in ascending order of the product_id.\n",
    "\n",
    "Table: products\n",
    "+-------------+-----------+\n",
    "| COLUMN_NAME | DATA_TYPE |\n",
    "+-------------+-----------+\n",
    "| product_id  | int       |\n",
    "| price       | int       |\n",
    "| price_date  | date      |\n",
    "+-------------+-----------+\n",
    "Table: orders \n",
    "+-------------+-----------+\n",
    "| COLUMN_NAME | DATA_TYPE |\n",
    "+-------------+-----------+\n",
    "| order_id    | int       |\n",
    "| order_date  | date      |\n",
    "| product_id  | int       |\n",
    "+-------------+-----------+\n",
    "\n",
    "+------------+------------+-------+\n",
    "| product_id | price_date | price |\n",
    "+------------+------------+-------+\n",
    "|        100 | 2024-01-01 |   150 |\n",
    "|        100 | 2024-01-21 |   170 |\n",
    "|        100 | 2024-02-01 |   190 |\n",
    "|        101 | 2024-01-01 |  1000 |\n",
    "|        101 | 2024-01-27 |  1200 |\n",
    "|        101 | 2024-02-05 |  1250 |\n",
    "|        102 | 2024-01-01 |    50 |\n",
    "|        102 | 2024-01-15 |    60 |\n",
    "|        102 | 2024-02-01 |    80 |\n",
    "|        103 | 2024-01-01 |   200 |\n",
    "|        103 | 2024-01-18 |   230 |\n",
    "|        104 | 2024-01-03 |   500 |\n",
    "|        104 | 2024-02-01 |   550 |\n",
    "|        105 | 2024-01-10 |   300 |\n",
    "|        106 | 2024-01-05 |   120 |\n",
    "|        106 | 2024-01-25 |   140 |\n",
    "|        107 | 2024-02-01 |   900 |\n",
    "|        108 | 2024-01-04 |   160 |\n",
    "|        108 | 2024-02-06 |   190 |\n",
    "|        109 | 2024-01-02 |    40 |\n",
    "+------------+------------+-------+\n",
    "+----------+------------+------------+\n",
    "| order_id | order_date | product_id |\n",
    "+----------+------------+------------+\n",
    "|        1 | 2024-01-05 |        100 |\n",
    "|        2 | 2024-01-21 |        100 |\n",
    "|        3 | 2024-02-20 |        100 |\n",
    "|        4 | 2024-01-07 |        101 |\n",
    "|        5 | 2024-02-04 |        101 |\n",
    "|        6 | 2024-02-05 |        101 |\n",
    "|        7 | 2024-02-10 |        101 |\n",
    "|        8 | 2024-01-02 |        102 |\n",
    "|        9 | 2024-01-16 |        102 |\n",
    "|       10 | 2024-02-10 |        102 |\n",
    "|       11 | 2024-01-10 |        103 |\n",
    "|       12 | 2024-01-25 |        103 |\n",
    "|       13 | 2024-01-20 |        104 |\n",
    "|       14 | 2024-02-03 |        105 |\n",
    "|       15 | 2024-01-06 |        106 |\n",
    "|       16 | 2024-01-28 |        106 |\n",
    "|       17 | 2024-02-05 |        107 |\n",
    "|       18 | 2024-02-08 |        108 |\n",
    "|       19 | 2024-01-03 |        109 |\n",
    "|       20 | 2024-01-15 |        109 |\n",
    "+----------+------------+------------+\n",
    "\n",
    "\n",
    "Output\n",
    "+------------+-------------+\n",
    "| product_id | total_sales |\n",
    "+------------+-------------+\n",
    "|        100 |         510 |\n",
    "|        101 |        4700 |\n",
    "|        102 |         190 |\n",
    "|        103 |         430 |\n",
    "|        104 |         500 |\n",
    "|        105 |         300 |\n",
    "|        106 |         260 |\n",
    "|        107 |         900 |\n",
    "|        108 |         190 |\n",
    "|        109 |          80 |\n",
    "+------------+-------------+\n",
    "\"\"\"\n",
    "\n",
    "products_df = spark.createDataFrame(\n",
    "    [\n",
    "        (100,'2024-01-01',150),\n",
    "        (100,'2024-01-21',170),\n",
    "        (100,'2024-02-01',190),\n",
    "        (101,'2024-01-01',1000),\n",
    "        (101,'2024-01-27',1200),\n",
    "        (101,'2024-02-05',1250),\n",
    "        (102,'2024-01-01',50),\n",
    "        (102,'2024-01-15',60),\n",
    "        (102,'2024-02-01',80),\n",
    "        (103,'2024-01-01',200),\n",
    "        (103,'2024-01-18',230),\n",
    "        (104,'2024-01-03',500),\n",
    "        (104,'2024-02-01',550),\n",
    "        (105,'2024-01-10',300),\n",
    "        (106,'2024-01-05',120),\n",
    "        (106,'2024-01-25',140),\n",
    "        (107,'2024-02-01',900),\n",
    "        (108,'2024-01-04',160),\n",
    "        (108,'2024-02-06',190),\n",
    "        (109,'2024-01-02',40)\n",
    "    ], [\"product_id\", \"price_date\", \"price\"]\n",
    ")\n",
    "\n",
    "orders_df = spark.createDataFrame(\n",
    "    [\n",
    "        (1,'2024-01-05',100),\n",
    "        (2,'2024-01-21',100),\n",
    "        (3,'2024-02-20',100),\n",
    "        (4,'2024-01-07',101),\n",
    "        (5,'2024-02-04',101),\n",
    "        (6,'2024-02-05',101),\n",
    "        (7,'2024-02-10',101),\n",
    "        (8,'2024-01-02',102),\n",
    "        (9,'2024-01-16',102),\n",
    "        (10,'2024-02-10',102),\n",
    "        (11,'2024-01-10',103),\n",
    "        (12,'2024-01-25',103),\n",
    "        (13,'2024-01-20',104),\n",
    "        (14,'2024-02-03',105),\n",
    "        (15,'2024-01-06',106),\n",
    "        (16,'2024-01-28',106),\n",
    "        (17,'2024-02-05',107),\n",
    "        (18,'2024-02-08',108),\n",
    "        (19,'2024-01-03',109),\n",
    "        (20,'2024-01-15',109)\n",
    "    ], [\"order_id\", \"order_date\", \"product_id\"]\n",
    ")\n",
    "\n",
    "products_df.show()\n",
    "orders_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af7e1484-aec1-4aeb-b138-01088d419ff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n|product_id|total_sales|\n+----------+-----------+\n|       100|        510|\n|       101|       4700|\n|       102|        190|\n|       103|        430|\n|       104|        500|\n|       105|        300|\n|       106|        260|\n|       107|        900|\n|       108|        190|\n|       109|         80|\n+----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import *\n",
    "\n",
    "\n",
    "orders_df.join(products_df, ((orders_df.product_id == products_df.product_id) & (orders_df.order_date >= products_df.price_date)), \"left\") \\\n",
    "    .withColumn(\"rn\", row_number().over(Window.partitionBy(col(\"order_id\")).orderBy(col(\"price_date\").desc()))) \\\n",
    "    .filter(col(\"rn\")==lit(1)) \\\n",
    "    .groupBy(orders_df.product_id).agg(sum(col(\"price\")).alias(\"total_sales\")) \\\n",
    "    .orderBy(orders_df.product_id) \\\n",
    "    .show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a5a5fffe-d09b-46d7-aa6e-e18dc207408f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n|product_id|total_sales|\n+----------+-----------+\n|       100|        510|\n|       101|       4700|\n|       102|        190|\n|       103|        430|\n|       104|        500|\n|       105|        300|\n|       106|        260|\n|       107|        900|\n|       108|        190|\n|       109|         80|\n+----------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "orders_df.createOrReplaceTempView(\"orders\")\n",
    "products_df.createOrReplaceTempView(\"products\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "            with  cte as (\n",
    "            select \n",
    "                o.*, \n",
    "                p.price, \n",
    "                p.price_date, \n",
    "                row_number() over (partition by order_id order by price_date desc) as rn \n",
    "            from orders o left join products p\n",
    "            on o.product_id = p.product_id and o.order_date >= p.price_date\n",
    "            )\n",
    "            select \n",
    "                product_id, \n",
    "                sum(price) as total_sales \n",
    "            from cte \n",
    "            where rn = 1 \n",
    "            group by product_id\n",
    "            order by product_id     \n",
    "          \"\"\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "20260102 Dynamic Pricing NamasteSQL Medium Walmart",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}